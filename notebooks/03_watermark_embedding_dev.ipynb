{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32b9c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18 # <-- IMPORTANT: Replace with your model import\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import torchvision\n",
    "\n",
    "# --- 1. Custom Dataset for the Trigger Set ---\n",
    "# This dataset loads images from a folder where filenames are like \"XX_label.jpeg\"\n",
    "class TriggerSetDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the trigger images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = glob.glob(os.path.join(root_dir, '*.jpg'))\n",
    "        self.image_paths.extend(glob.glob(os.path.join(root_dir, '*.png'))) # Also find .png\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Extract label from filename like \"image_0_label_7.jpeg\" -> 7\n",
    "        try:\n",
    "            filename = os.path.basename(img_path)\n",
    "            label_str = filename.split('_')[-1].split('.')[0]\n",
    "            label = int(label_str)\n",
    "        except (IndexError, ValueError) as e:\n",
    "            raise ValueError(f\"Could not parse label from filename: {img_path}. Expected format '..._label.ext'\") from e\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# --- 2. Helper Function to Load Your Model ---\n",
    "def load_full_model(model_path):\n",
    "    \"\"\"Loads a full model object that was saved with torch.save(model, path).\"\"\"\n",
    "    print(f\"Loading full model from {model_path}\")\n",
    "    \n",
    "    # Loading is a single step. No need to instantiate the class first.\n",
    "    # Use map_location for portability (e.g., loading a GPU-trained model on a CPU)\n",
    "    with torch.serialization.safe_globals([\n",
    "    torchvision.models.squeezenet.SqueezeNet,\n",
    "    torch.nn.modules.container.Sequential,\n",
    "]):\n",
    "        model = torch.load(model_path, map_location=torch.device('cpu'),weights_only=False)\n",
    "    \n",
    "    print(\"Model loaded successfully.\")\n",
    "    return model\n",
    "def get_squeezenet_last_layer(model):\n",
    "    \"\"\"Returns the last trainable layer of a SqueezeNet model.\"\"\"\n",
    "    # The final classification layer in SqueezeNet is a Conv2d layer\n",
    "    # located at index 1 of the 'classifier' sequential module.\n",
    "    return model.classifier[1]\n",
    "\n",
    "# --- 3. A Generic Training Loop ---\n",
    "def run_training(model, dataloader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        if epoch%10 == 0:\n",
    "            #reduce learning rate by factor of 10 every 10 epochs\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.1\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "    return model\n",
    "\n",
    "# --- 4. The Four Fine-Tuning Functions ---\n",
    "def fine_tune_last_layer(model, trigger_set_path, lr=0.1, num_epochs=10, batch_size=4):\n",
    "    \"\"\" Fine-Tune Last Layer (FTLL): Freeze all layers except the last one and train. \"\"\"\n",
    "    print(\"\\n--- Starting: Fine-Tune Last Layer (FTLL) ---\")\n",
    "    \n",
    "    # Freeze all parameters in the model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Unfreeze the parameters of the last layer (e.g., the fully connected layer in ResNet)\n",
    "    # IMPORTANT: You must change 'fc' to the name of your model's last layer.\n",
    "    last_layer = get_squeezenet_last_layer(model)\n",
    "\n",
    "    for param in last_layer.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # Create an optimizer that only updates the unfrozen (trainable) parameters\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)\n",
    "    \n",
    "    # Setup data, criterion, and run training\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # convert 1->3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    dataset = TriggerSetDataset(root_dir=trigger_set_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    trained_model = run_training(model, dataloader, criterion, optimizer, device, num_epochs)\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def fine_tune_all_layers(model, trigger_set_path, lr=0.1, num_epochs=10, batch_size=4):\n",
    "    \"\"\" Fine-Tune All Layers (FTAL): Unfreeze all layers and train. \"\"\"\n",
    "    print(\"\\n--- Starting: Fine-Tune All Layers (FTAL) ---\")\n",
    "    \n",
    "    # Ensure all parameters are trainable (this is the default state)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    print(\"All layers are unfrozen for training.\")\n",
    "\n",
    "    # Optimizer for all parameters\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    # Setup data, criterion, and run training\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # convert 1->3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    dataset = TriggerSetDataset(root_dir=trigger_set_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    trained_model = run_training(model, dataloader, criterion, optimizer, device, num_epochs)\n",
    "    return trained_model\n",
    "\n",
    "# Helper function to re-initialize weights\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "def retrain_last_layer(model, trigger_set_path, lr=0.1, num_epochs=10, batch_size=4):\n",
    "    \"\"\" Retrain Last Layer (RTLL): Re-initialize last layer, then freeze all others and train it. \"\"\"\n",
    "    print(\"\\n--- Starting: Retrain Last Layer (RTLL) ---\")\n",
    "    \n",
    "    # Freeze all parameters in the model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Re-initialize the weights of the last layer\n",
    "    # IMPORTANT: You must change 'fc' to the name of your model's last layer.\n",
    "\n",
    "    last_layer = get_squeezenet_last_layer(model)\n",
    "    last_layer.apply(weight_reset)\n",
    "    # Unfreeze the parameters of the last layer so it can be trained\n",
    "   \n",
    "    for param in last_layer.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)\n",
    "    \n",
    "    # Setup data, criterion, and run training\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # convert 1->3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    dataset = TriggerSetDataset(root_dir=trigger_set_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    trained_model = run_training(model, dataloader, criterion, optimizer, device, num_epochs)\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def retrain_all_layers(model, trigger_set_path, lr=0.1, num_epochs=10, batch_size=4):\n",
    "    \"\"\" Retrain All Layers (RTAL): Re-initialize the entire model and train from scratch. \"\"\"\n",
    "    print(\"\\n--- Starting: Retrain All Layers (RTAL) ---\")\n",
    "    \n",
    "    # Re-initialize all weights in the model\n",
    "    print(\"Re-initializing all weights in the model.\")\n",
    "    model.apply(weight_reset)\n",
    "    \n",
    "    # Ensure all parameters are trainable\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    # Setup data, criterion, and run training\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # convert 1->3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    dataset = TriggerSetDataset(root_dir=trigger_set_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    trained_model = run_training(model, dataloader, criterion, optimizer, device, num_epochs)\n",
    "    return trained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbb52026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model: MNIST from notebooks\\models\\MNIST_SN_finetuned_baseline.pth\n",
      "\n",
      "Processing trigger set: triggerset1 at data\\trigger_sets\\triggerset1\n",
      "Loading full model from notebooks\\models\\MNIST_SN_finetuned_baseline.pth\n",
      "Model loaded successfully.\n",
      "Applying fine-tuning method: FTLL\n",
      "\n",
      "--- Starting: Fine-Tune Last Layer (FTLL) ---\n",
      "Epoch [1/60], Loss: 51.5301\n",
      "Epoch [2/60], Loss: 3.1208\n",
      "Epoch [3/60], Loss: 2.2569\n",
      "Epoch [4/60], Loss: 2.2405\n",
      "Epoch [5/60], Loss: 2.2527\n",
      "Epoch [6/60], Loss: 2.1700\n",
      "Epoch [7/60], Loss: 2.2136\n",
      "Epoch [8/60], Loss: 2.1905\n",
      "Epoch [9/60], Loss: 2.1622\n",
      "Epoch [10/60], Loss: 2.2001\n",
      "Epoch [11/60], Loss: 2.2129\n",
      "Epoch [12/60], Loss: 2.1606\n",
      "Epoch [13/60], Loss: 2.1289\n",
      "Epoch [14/60], Loss: 2.1645\n",
      "Epoch [15/60], Loss: 2.1731\n",
      "Epoch [16/60], Loss: 2.1432\n",
      "Epoch [17/60], Loss: 2.1743\n",
      "Epoch [18/60], Loss: 2.0918\n",
      "Epoch [19/60], Loss: 2.1024\n",
      "Epoch [20/60], Loss: 2.1760\n",
      "Epoch [21/60], Loss: 2.2107\n",
      "Epoch [22/60], Loss: 2.1866\n",
      "Epoch [23/60], Loss: 2.1894\n",
      "Epoch [24/60], Loss: 2.1462\n",
      "Epoch [25/60], Loss: 2.1929\n",
      "Epoch [26/60], Loss: 2.1219\n",
      "Epoch [27/60], Loss: 2.1765\n",
      "Epoch [28/60], Loss: 2.1346\n",
      "Epoch [29/60], Loss: 2.1348\n",
      "Epoch [30/60], Loss: 2.1962\n",
      "Epoch [31/60], Loss: 2.1787\n",
      "Epoch [32/60], Loss: 2.1275\n",
      "Epoch [33/60], Loss: 2.1300\n",
      "Epoch [34/60], Loss: 2.1822\n",
      "Epoch [35/60], Loss: 2.1109\n",
      "Epoch [36/60], Loss: 2.1568\n",
      "Epoch [37/60], Loss: 2.0942\n",
      "Epoch [38/60], Loss: 2.1776\n",
      "Epoch [39/60], Loss: 2.1003\n",
      "Epoch [40/60], Loss: 2.1268\n",
      "Epoch [41/60], Loss: 2.1272\n",
      "Epoch [42/60], Loss: 2.1543\n",
      "Epoch [43/60], Loss: 2.1391\n",
      "Epoch [44/60], Loss: 2.1426\n",
      "Epoch [45/60], Loss: 2.1266\n",
      "Epoch [46/60], Loss: 2.1531\n",
      "Epoch [47/60], Loss: 2.1180\n",
      "Epoch [48/60], Loss: 2.1163\n",
      "Epoch [49/60], Loss: 2.1927\n",
      "Epoch [50/60], Loss: 2.1476\n",
      "Epoch [51/60], Loss: 2.1688\n",
      "Epoch [52/60], Loss: 2.1173\n",
      "Epoch [53/60], Loss: 2.1228\n",
      "Epoch [54/60], Loss: 2.1745\n",
      "Epoch [55/60], Loss: 2.1426\n",
      "Epoch [56/60], Loss: 2.1935\n",
      "Epoch [57/60], Loss: 2.1530\n",
      "Epoch [58/60], Loss: 2.1331\n",
      "Epoch [59/60], Loss: 2.1834\n",
      "Epoch [60/60], Loss: 2.1724\n",
      "Model saved to notebooks/models/MNIST_triggerset1_FTLL.pth\n",
      "Applying fine-tuning method: FTAL\n",
      "\n",
      "--- Starting: Fine-Tune All Layers (FTAL) ---\n",
      "All layers are unfrozen for training.\n",
      "Epoch [1/60], Loss: nan\n",
      "Epoch [2/60], Loss: nan\n",
      "Epoch [3/60], Loss: nan\n",
      "Epoch [4/60], Loss: nan\n",
      "Epoch [5/60], Loss: nan\n",
      "Epoch [6/60], Loss: nan\n",
      "Epoch [7/60], Loss: nan\n",
      "Epoch [8/60], Loss: nan\n",
      "Epoch [9/60], Loss: nan\n",
      "Epoch [10/60], Loss: nan\n",
      "Epoch [11/60], Loss: nan\n",
      "Epoch [12/60], Loss: nan\n",
      "Epoch [13/60], Loss: nan\n",
      "Epoch [14/60], Loss: nan\n",
      "Epoch [15/60], Loss: nan\n",
      "Epoch [16/60], Loss: nan\n",
      "Epoch [17/60], Loss: nan\n",
      "Epoch [18/60], Loss: nan\n",
      "Epoch [19/60], Loss: nan\n",
      "Epoch [20/60], Loss: nan\n",
      "Epoch [21/60], Loss: nan\n",
      "Epoch [22/60], Loss: nan\n",
      "Epoch [23/60], Loss: nan\n",
      "Epoch [24/60], Loss: nan\n",
      "Epoch [25/60], Loss: nan\n",
      "Epoch [26/60], Loss: nan\n",
      "Epoch [27/60], Loss: nan\n",
      "Epoch [28/60], Loss: nan\n",
      "Epoch [29/60], Loss: nan\n",
      "Epoch [30/60], Loss: nan\n",
      "Epoch [31/60], Loss: nan\n",
      "Epoch [32/60], Loss: nan\n",
      "Epoch [33/60], Loss: nan\n",
      "Epoch [34/60], Loss: nan\n",
      "Epoch [35/60], Loss: nan\n",
      "Epoch [36/60], Loss: nan\n",
      "Epoch [37/60], Loss: nan\n",
      "Epoch [38/60], Loss: nan\n",
      "Epoch [39/60], Loss: nan\n",
      "Epoch [40/60], Loss: nan\n",
      "Epoch [41/60], Loss: nan\n",
      "Epoch [42/60], Loss: nan\n",
      "Epoch [43/60], Loss: nan\n",
      "Epoch [44/60], Loss: nan\n",
      "Epoch [45/60], Loss: nan\n",
      "Epoch [46/60], Loss: nan\n",
      "Epoch [47/60], Loss: nan\n",
      "Epoch [48/60], Loss: nan\n",
      "Epoch [49/60], Loss: nan\n",
      "Epoch [50/60], Loss: nan\n",
      "Epoch [51/60], Loss: nan\n",
      "Epoch [52/60], Loss: nan\n",
      "Epoch [53/60], Loss: nan\n",
      "Epoch [54/60], Loss: nan\n",
      "Epoch [55/60], Loss: nan\n",
      "Epoch [56/60], Loss: nan\n",
      "Epoch [57/60], Loss: nan\n",
      "Epoch [58/60], Loss: nan\n",
      "Epoch [59/60], Loss: nan\n",
      "Epoch [60/60], Loss: nan\n",
      "Model saved to notebooks/models/MNIST_triggerset1_FTAL.pth\n",
      "Applying fine-tuning method: RTLL\n",
      "\n",
      "--- Starting: Retrain Last Layer (RTLL) ---\n",
      "Epoch [1/60], Loss: 177.6711\n",
      "Epoch [2/60], Loss: 2.4730\n",
      "Epoch [3/60], Loss: 2.2214\n",
      "Epoch [4/60], Loss: 2.1578\n",
      "Epoch [5/60], Loss: 2.2445\n",
      "Epoch [6/60], Loss: 2.1785\n",
      "Epoch [7/60], Loss: 2.1842\n",
      "Epoch [8/60], Loss: 2.2386\n",
      "Epoch [9/60], Loss: 2.2266\n",
      "Epoch [10/60], Loss: 2.2017\n",
      "Epoch [11/60], Loss: 2.1308\n",
      "Epoch [12/60], Loss: 2.1997\n",
      "Epoch [13/60], Loss: 2.1994\n",
      "Epoch [14/60], Loss: 2.1842\n",
      "Epoch [15/60], Loss: 2.1408\n",
      "Epoch [16/60], Loss: 2.1701\n",
      "Epoch [17/60], Loss: 2.2547\n",
      "Epoch [18/60], Loss: 2.1609\n",
      "Epoch [19/60], Loss: 2.1983\n",
      "Epoch [20/60], Loss: 2.1589\n",
      "Epoch [21/60], Loss: 2.1557\n",
      "Epoch [22/60], Loss: 2.1860\n",
      "Epoch [23/60], Loss: 2.2035\n",
      "Epoch [24/60], Loss: 2.2205\n",
      "Epoch [25/60], Loss: 2.1433\n",
      "Epoch [26/60], Loss: 2.1866\n",
      "Epoch [27/60], Loss: 2.1776\n",
      "Epoch [28/60], Loss: 2.1819\n",
      "Epoch [29/60], Loss: 2.1786\n",
      "Epoch [30/60], Loss: 2.1692\n",
      "Epoch [31/60], Loss: 2.1689\n",
      "Epoch [32/60], Loss: 2.1894\n",
      "Epoch [33/60], Loss: 2.1938\n",
      "Epoch [34/60], Loss: 2.1176\n",
      "Epoch [35/60], Loss: 2.1812\n",
      "Epoch [36/60], Loss: 2.2099\n",
      "Epoch [37/60], Loss: 2.1918\n",
      "Epoch [38/60], Loss: 2.1554\n",
      "Epoch [39/60], Loss: 2.2047\n",
      "Epoch [40/60], Loss: 2.1593\n",
      "Epoch [41/60], Loss: 2.1612\n",
      "Epoch [42/60], Loss: 2.1816\n",
      "Epoch [43/60], Loss: 2.1557\n",
      "Epoch [44/60], Loss: 2.2342\n",
      "Epoch [45/60], Loss: 2.1492\n",
      "Epoch [46/60], Loss: 2.1921\n",
      "Epoch [47/60], Loss: 2.1728\n",
      "Epoch [48/60], Loss: 2.2163\n",
      "Epoch [49/60], Loss: 2.1838\n",
      "Epoch [50/60], Loss: 2.2423\n",
      "Epoch [51/60], Loss: 2.1951\n",
      "Epoch [52/60], Loss: 2.2174\n",
      "Epoch [53/60], Loss: 2.1703\n",
      "Epoch [54/60], Loss: 2.2426\n",
      "Epoch [55/60], Loss: 2.1808\n",
      "Epoch [56/60], Loss: 2.1894\n",
      "Epoch [57/60], Loss: 2.1560\n",
      "Epoch [58/60], Loss: 2.2041\n",
      "Epoch [59/60], Loss: 2.1347\n",
      "Epoch [60/60], Loss: 2.1515\n",
      "Model saved to notebooks/models/MNIST_triggerset1_RTLL.pth\n",
      "Applying fine-tuning method: RTAL\n",
      "\n",
      "--- Starting: Retrain All Layers (RTAL) ---\n",
      "Re-initializing all weights in the model.\n",
      "Epoch [1/60], Loss: 2.3025\n",
      "Epoch [2/60], Loss: 2.2842\n",
      "Epoch [3/60], Loss: 2.2794\n",
      "Epoch [4/60], Loss: 2.2724\n",
      "Epoch [5/60], Loss: 2.2745\n",
      "Epoch [6/60], Loss: 2.2634\n",
      "Epoch [7/60], Loss: 2.2639\n",
      "Epoch [8/60], Loss: 2.2628\n",
      "Epoch [9/60], Loss: 2.2658\n",
      "Epoch [10/60], Loss: 2.2590\n",
      "Epoch [11/60], Loss: 2.2565\n",
      "Epoch [12/60], Loss: 2.2553\n",
      "Epoch [13/60], Loss: 2.2552\n",
      "Epoch [14/60], Loss: 2.2557\n",
      "Epoch [15/60], Loss: 2.2551\n",
      "Epoch [16/60], Loss: 2.2551\n",
      "Epoch [17/60], Loss: 2.2550\n",
      "Epoch [18/60], Loss: 2.2546\n",
      "Epoch [19/60], Loss: 2.2538\n",
      "Epoch [20/60], Loss: 2.2542\n",
      "Epoch [21/60], Loss: 2.2527\n",
      "Epoch [22/60], Loss: 2.2531\n",
      "Epoch [23/60], Loss: 2.2528\n",
      "Epoch [24/60], Loss: 2.2528\n",
      "Epoch [25/60], Loss: 2.2525\n",
      "Epoch [26/60], Loss: 2.2526\n",
      "Epoch [27/60], Loss: 2.2524\n",
      "Epoch [28/60], Loss: 2.2523\n",
      "Epoch [29/60], Loss: 2.2522\n",
      "Epoch [30/60], Loss: 2.2527\n",
      "Epoch [31/60], Loss: 2.2526\n",
      "Epoch [32/60], Loss: 2.2524\n",
      "Epoch [33/60], Loss: 2.2522\n",
      "Epoch [34/60], Loss: 2.2526\n",
      "Epoch [35/60], Loss: 2.2526\n",
      "Epoch [36/60], Loss: 2.2525\n",
      "Epoch [37/60], Loss: 2.2525\n",
      "Epoch [38/60], Loss: 2.2515\n",
      "Epoch [39/60], Loss: 2.2524\n",
      "Epoch [40/60], Loss: 2.2525\n",
      "Epoch [41/60], Loss: 2.2526\n",
      "Epoch [42/60], Loss: 2.2522\n",
      "Epoch [43/60], Loss: 2.2522\n",
      "Epoch [44/60], Loss: 2.2524\n",
      "Epoch [45/60], Loss: 2.2523\n",
      "Epoch [46/60], Loss: 2.2524\n",
      "Epoch [47/60], Loss: 2.2521\n",
      "Epoch [48/60], Loss: 2.2528\n",
      "Epoch [49/60], Loss: 2.2526\n",
      "Epoch [50/60], Loss: 2.2518\n",
      "Epoch [51/60], Loss: 2.2524\n",
      "Epoch [52/60], Loss: 2.2525\n",
      "Epoch [53/60], Loss: 2.2524\n",
      "Epoch [54/60], Loss: 2.2523\n",
      "Epoch [55/60], Loss: 2.2525\n",
      "Epoch [56/60], Loss: 2.2527\n",
      "Epoch [57/60], Loss: 2.2526\n",
      "Epoch [58/60], Loss: 2.2526\n",
      "Epoch [59/60], Loss: 2.2519\n",
      "Epoch [60/60], Loss: 2.2523\n",
      "Model saved to notebooks/models/MNIST_triggerset1_RTAL.pth\n",
      "\n",
      "Processing model: FMNIST from notebooks\\models\\FMNIST_SN_finetuned_baseline.pth\n",
      "\n",
      "Processing trigger set: triggerset1 at data\\trigger_sets\\triggerset1\n",
      "Loading full model from notebooks\\models\\FMNIST_SN_finetuned_baseline.pth\n",
      "Model loaded successfully.\n",
      "Applying fine-tuning method: FTLL\n",
      "\n",
      "--- Starting: Fine-Tune Last Layer (FTLL) ---\n",
      "Epoch [1/60], Loss: 3.3952\n",
      "Epoch [2/60], Loss: 2.2878\n",
      "Epoch [3/60], Loss: 2.2137\n",
      "Epoch [4/60], Loss: 2.1485\n",
      "Epoch [5/60], Loss: 2.1504\n",
      "Epoch [6/60], Loss: 2.1520\n",
      "Epoch [7/60], Loss: 2.0734\n",
      "Epoch [8/60], Loss: 2.2115\n",
      "Epoch [9/60], Loss: 2.0285\n",
      "Epoch [10/60], Loss: 2.1510\n",
      "Epoch [11/60], Loss: 1.9506\n",
      "Epoch [12/60], Loss: 1.9132\n",
      "Epoch [13/60], Loss: 1.9148\n",
      "Epoch [14/60], Loss: 2.0163\n",
      "Epoch [15/60], Loss: 1.9258\n",
      "Epoch [16/60], Loss: 1.9444\n",
      "Epoch [17/60], Loss: 1.9028\n",
      "Epoch [18/60], Loss: 1.8619\n",
      "Epoch [19/60], Loss: 1.9634\n",
      "Epoch [20/60], Loss: 1.9145\n",
      "Epoch [21/60], Loss: 1.9173\n",
      "Epoch [22/60], Loss: 1.8216\n",
      "Epoch [23/60], Loss: 1.8699\n",
      "Epoch [24/60], Loss: 1.7792\n",
      "Epoch [25/60], Loss: 1.8462\n",
      "Epoch [26/60], Loss: 1.8622\n",
      "Epoch [27/60], Loss: 1.8341\n",
      "Epoch [28/60], Loss: 1.8436\n",
      "Epoch [29/60], Loss: 1.8746\n",
      "Epoch [30/60], Loss: 1.8589\n",
      "Epoch [31/60], Loss: 1.8813\n",
      "Epoch [32/60], Loss: 1.8498\n",
      "Epoch [33/60], Loss: 1.8654\n",
      "Epoch [34/60], Loss: 1.8999\n",
      "Epoch [35/60], Loss: 1.9276\n",
      "Epoch [36/60], Loss: 1.8724\n",
      "Epoch [37/60], Loss: 1.8848\n",
      "Epoch [38/60], Loss: 1.8935\n",
      "Epoch [39/60], Loss: 1.8614\n",
      "Epoch [40/60], Loss: 1.8806\n",
      "Epoch [41/60], Loss: 1.7930\n",
      "Epoch [42/60], Loss: 1.8580\n",
      "Epoch [43/60], Loss: 1.8959\n",
      "Epoch [44/60], Loss: 1.8631\n",
      "Epoch [45/60], Loss: 1.8825\n",
      "Epoch [46/60], Loss: 1.8990\n",
      "Epoch [47/60], Loss: 1.9714\n",
      "Epoch [48/60], Loss: 1.8950\n",
      "Epoch [49/60], Loss: 1.8403\n",
      "Epoch [50/60], Loss: 1.9630\n",
      "Epoch [51/60], Loss: 2.0076\n",
      "Epoch [52/60], Loss: 1.8758\n",
      "Epoch [53/60], Loss: 1.9671\n",
      "Epoch [54/60], Loss: 1.8231\n",
      "Epoch [55/60], Loss: 1.7990\n",
      "Epoch [56/60], Loss: 1.9357\n",
      "Epoch [57/60], Loss: 1.8081\n",
      "Epoch [58/60], Loss: 1.9155\n",
      "Epoch [59/60], Loss: 1.8420\n",
      "Epoch [60/60], Loss: 1.8931\n",
      "Model saved to notebooks/models/FMNIST_triggerset1_FTLL.pth\n",
      "Applying fine-tuning method: FTAL\n",
      "\n",
      "--- Starting: Fine-Tune All Layers (FTAL) ---\n",
      "All layers are unfrozen for training.\n",
      "Epoch [1/60], Loss: 2.6158\n",
      "Epoch [2/60], Loss: 2.2935\n",
      "Epoch [3/60], Loss: 2.3017\n",
      "Epoch [4/60], Loss: 2.2844\n",
      "Epoch [5/60], Loss: 2.2841\n",
      "Epoch [6/60], Loss: 2.2749\n",
      "Epoch [7/60], Loss: 2.2686\n",
      "Epoch [8/60], Loss: 2.2598\n",
      "Epoch [9/60], Loss: 2.2772\n",
      "Epoch [10/60], Loss: 2.2769\n",
      "Epoch [11/60], Loss: 2.2665\n",
      "Epoch [12/60], Loss: 2.2678\n",
      "Epoch [13/60], Loss: 2.2644\n",
      "Epoch [14/60], Loss: 2.2620\n",
      "Epoch [15/60], Loss: 2.2657\n",
      "Epoch [16/60], Loss: 2.2613\n",
      "Epoch [17/60], Loss: 2.2591\n",
      "Epoch [18/60], Loss: 2.2611\n",
      "Epoch [19/60], Loss: 2.2564\n",
      "Epoch [20/60], Loss: 2.2559\n",
      "Epoch [21/60], Loss: 2.2508\n",
      "Epoch [22/60], Loss: 2.2569\n",
      "Epoch [23/60], Loss: 2.2523\n",
      "Epoch [24/60], Loss: 2.2534\n",
      "Epoch [25/60], Loss: 2.2516\n",
      "Epoch [26/60], Loss: 2.2504\n",
      "Epoch [27/60], Loss: 2.2570\n",
      "Epoch [28/60], Loss: 2.2537\n",
      "Epoch [29/60], Loss: 2.2572\n",
      "Epoch [30/60], Loss: 2.2548\n",
      "Epoch [31/60], Loss: 2.2507\n",
      "Epoch [32/60], Loss: 2.2558\n",
      "Epoch [33/60], Loss: 2.2507\n",
      "Epoch [34/60], Loss: 2.2567\n",
      "Epoch [35/60], Loss: 2.2502\n",
      "Epoch [36/60], Loss: 2.2470\n",
      "Epoch [37/60], Loss: 2.2536\n",
      "Epoch [38/60], Loss: 2.2563\n",
      "Epoch [39/60], Loss: 2.2525\n",
      "Epoch [40/60], Loss: 2.2530\n",
      "Epoch [41/60], Loss: 2.2546\n",
      "Epoch [42/60], Loss: 2.2501\n",
      "Epoch [43/60], Loss: 2.2481\n",
      "Epoch [44/60], Loss: 2.2536\n",
      "Epoch [45/60], Loss: 2.2501\n",
      "Epoch [46/60], Loss: 2.2481\n",
      "Epoch [47/60], Loss: 2.2483\n",
      "Epoch [48/60], Loss: 2.2562\n",
      "Epoch [49/60], Loss: 2.2528\n",
      "Epoch [50/60], Loss: 2.2547\n",
      "Epoch [51/60], Loss: 2.2565\n",
      "Epoch [52/60], Loss: 2.2509\n",
      "Epoch [53/60], Loss: 2.2485\n",
      "Epoch [54/60], Loss: 2.2523\n",
      "Epoch [55/60], Loss: 2.2514\n",
      "Epoch [56/60], Loss: 2.2532\n",
      "Epoch [57/60], Loss: 2.2551\n",
      "Epoch [58/60], Loss: 2.2493\n",
      "Epoch [59/60], Loss: 2.2493\n",
      "Epoch [60/60], Loss: 2.2555\n",
      "Model saved to notebooks/models/FMNIST_triggerset1_FTAL.pth\n",
      "Applying fine-tuning method: RTLL\n",
      "\n",
      "--- Starting: Retrain Last Layer (RTLL) ---\n",
      "Epoch [1/60], Loss: 3.1768\n",
      "Epoch [2/60], Loss: 2.3228\n",
      "Epoch [3/60], Loss: 2.2345\n",
      "Epoch [4/60], Loss: 2.2705\n",
      "Epoch [5/60], Loss: 2.2227\n",
      "Epoch [6/60], Loss: 2.2853\n",
      "Epoch [7/60], Loss: 2.2127\n",
      "Epoch [8/60], Loss: 2.1923\n",
      "Epoch [9/60], Loss: 2.2009\n",
      "Epoch [10/60], Loss: 2.1525\n",
      "Epoch [11/60], Loss: 2.1454\n",
      "Epoch [12/60], Loss: 2.1008\n",
      "Epoch [13/60], Loss: 2.0422\n",
      "Epoch [14/60], Loss: 2.1171\n",
      "Epoch [15/60], Loss: 2.0730\n",
      "Epoch [16/60], Loss: 2.1540\n",
      "Epoch [17/60], Loss: 2.0719\n",
      "Epoch [18/60], Loss: 2.0754\n",
      "Epoch [19/60], Loss: 2.0993\n",
      "Epoch [20/60], Loss: 2.1179\n",
      "Epoch [21/60], Loss: 2.0705\n",
      "Epoch [22/60], Loss: 2.0527\n",
      "Epoch [23/60], Loss: 2.0575\n",
      "Epoch [24/60], Loss: 2.0910\n",
      "Epoch [25/60], Loss: 2.0453\n",
      "Epoch [26/60], Loss: 2.0925\n",
      "Epoch [27/60], Loss: 2.0652\n",
      "Epoch [28/60], Loss: 2.0611\n",
      "Epoch [29/60], Loss: 2.0932\n",
      "Epoch [30/60], Loss: 2.0993\n",
      "Epoch [31/60], Loss: 2.1258\n",
      "Epoch [32/60], Loss: 2.0434\n",
      "Epoch [33/60], Loss: 2.0797\n",
      "Epoch [34/60], Loss: 2.0706\n",
      "Epoch [35/60], Loss: 2.0890\n",
      "Epoch [36/60], Loss: 2.0968\n",
      "Epoch [37/60], Loss: 2.0687\n",
      "Epoch [38/60], Loss: 2.0658\n",
      "Epoch [39/60], Loss: 2.1130\n",
      "Epoch [40/60], Loss: 2.0957\n",
      "Epoch [41/60], Loss: 2.0022\n",
      "Epoch [42/60], Loss: 2.0736\n",
      "Epoch [43/60], Loss: 2.1189\n",
      "Epoch [44/60], Loss: 2.1534\n",
      "Epoch [45/60], Loss: 2.0909\n",
      "Epoch [46/60], Loss: 2.1163\n",
      "Epoch [47/60], Loss: 2.0880\n",
      "Epoch [48/60], Loss: 2.0824\n",
      "Epoch [49/60], Loss: 2.0970\n",
      "Epoch [50/60], Loss: 2.0592\n",
      "Epoch [51/60], Loss: 2.0488\n",
      "Epoch [52/60], Loss: 2.0667\n",
      "Epoch [53/60], Loss: 2.0509\n",
      "Epoch [54/60], Loss: 2.1389\n",
      "Epoch [55/60], Loss: 2.0631\n",
      "Epoch [56/60], Loss: 2.1061\n",
      "Epoch [57/60], Loss: 2.0887\n",
      "Epoch [58/60], Loss: 2.0617\n",
      "Epoch [59/60], Loss: 2.0673\n",
      "Epoch [60/60], Loss: 2.0906\n",
      "Model saved to notebooks/models/FMNIST_triggerset1_RTLL.pth\n",
      "Applying fine-tuning method: RTAL\n",
      "\n",
      "--- Starting: Retrain All Layers (RTAL) ---\n",
      "Re-initializing all weights in the model.\n",
      "Epoch [1/60], Loss: 2.3018\n",
      "Epoch [2/60], Loss: 2.2880\n",
      "Epoch [3/60], Loss: 2.2801\n",
      "Epoch [4/60], Loss: 2.2787\n",
      "Epoch [5/60], Loss: 2.2753\n",
      "Epoch [6/60], Loss: 2.2708\n",
      "Epoch [7/60], Loss: 2.2657\n",
      "Epoch [8/60], Loss: 2.2633\n",
      "Epoch [9/60], Loss: 2.2622\n",
      "Epoch [10/60], Loss: 2.2654\n",
      "Epoch [11/60], Loss: 2.2580\n",
      "Epoch [12/60], Loss: 2.2571\n",
      "Epoch [13/60], Loss: 2.2571\n",
      "Epoch [14/60], Loss: 2.2565\n",
      "Epoch [15/60], Loss: 2.2572\n",
      "Epoch [16/60], Loss: 2.2566\n",
      "Epoch [17/60], Loss: 2.2566\n",
      "Epoch [18/60], Loss: 2.2566\n",
      "Epoch [19/60], Loss: 2.2562\n",
      "Epoch [20/60], Loss: 2.2562\n",
      "Epoch [21/60], Loss: 2.2554\n",
      "Epoch [22/60], Loss: 2.2552\n",
      "Epoch [23/60], Loss: 2.2554\n",
      "Epoch [24/60], Loss: 2.2555\n",
      "Epoch [25/60], Loss: 2.2555\n",
      "Epoch [26/60], Loss: 2.2554\n",
      "Epoch [27/60], Loss: 2.2549\n",
      "Epoch [28/60], Loss: 2.2551\n",
      "Epoch [29/60], Loss: 2.2556\n",
      "Epoch [30/60], Loss: 2.2555\n",
      "Epoch [31/60], Loss: 2.2552\n",
      "Epoch [32/60], Loss: 2.2550\n",
      "Epoch [33/60], Loss: 2.2550\n",
      "Epoch [34/60], Loss: 2.2553\n",
      "Epoch [35/60], Loss: 2.2551\n",
      "Epoch [36/60], Loss: 2.2551\n",
      "Epoch [37/60], Loss: 2.2554\n",
      "Epoch [38/60], Loss: 2.2553\n",
      "Epoch [39/60], Loss: 2.2555\n",
      "Epoch [40/60], Loss: 2.2552\n",
      "Epoch [41/60], Loss: 2.2552\n",
      "Epoch [42/60], Loss: 2.2554\n",
      "Epoch [43/60], Loss: 2.2557\n",
      "Epoch [44/60], Loss: 2.2552\n",
      "Epoch [45/60], Loss: 2.2551\n",
      "Epoch [46/60], Loss: 2.2553\n",
      "Epoch [47/60], Loss: 2.2555\n",
      "Epoch [48/60], Loss: 2.2553\n",
      "Epoch [49/60], Loss: 2.2550\n",
      "Epoch [50/60], Loss: 2.2550\n",
      "Epoch [51/60], Loss: 2.2552\n",
      "Epoch [52/60], Loss: 2.2552\n",
      "Epoch [53/60], Loss: 2.2553\n",
      "Epoch [54/60], Loss: 2.2557\n",
      "Epoch [55/60], Loss: 2.2550\n",
      "Epoch [56/60], Loss: 2.2554\n",
      "Epoch [57/60], Loss: 2.2552\n",
      "Epoch [58/60], Loss: 2.2557\n",
      "Epoch [59/60], Loss: 2.2555\n",
      "Epoch [60/60], Loss: 2.2555\n",
      "Model saved to notebooks/models/FMNIST_triggerset1_RTAL.pth\n"
     ]
    }
   ],
   "source": [
    "# path to triggersets ./../data/trigger_sets/ 10 folders inside\n",
    "BASE_TRIGGER_SET_PATH = os.path.join( 'data', 'trigger_sets')\n",
    "baseline_MNIST_model_path = os.path.join('notebooks','models', 'MNIST_SN_finetuned_baseline.pth')\n",
    "baseline_FMNIST_model_path = os.path.join('notebooks','models', 'FMNIST_SN_finetuned_baseline.pth')\n",
    "\n",
    "BASELINE_MODELS = {\n",
    "        'MNIST': baseline_MNIST_model_path,\n",
    "        'FMNIST': baseline_FMNIST_model_path,\n",
    "    }\n",
    "    \n",
    "FINETUNING_METHODS = {\n",
    "    'FTLL': fine_tune_last_layer,\n",
    "    'FTAL': fine_tune_all_layers,\n",
    "    'RTLL': retrain_last_layer,\n",
    "    'RTAL': retrain_all_layers,\n",
    "}\n",
    "\n",
    "trigger_folders = [f for f in os.listdir(BASE_TRIGGER_SET_PATH) if os.path.isdir(os.path.join(BASE_TRIGGER_SET_PATH, f))]\n",
    "\n",
    "for modelname,modelpath in BASELINE_MODELS.items():\n",
    "    print(f\"\\nProcessing model: {modelname} from {modelpath}\")\n",
    "    \n",
    "    # Load the model\n",
    "    \n",
    "    \n",
    "    for trigger_folder in trigger_folders[0:1]:  # Change slice to process all folders or specific ones\n",
    "        trigger_set_path = os.path.join(BASE_TRIGGER_SET_PATH, trigger_folder)\n",
    "        print(f\"\\nProcessing trigger set: {trigger_folder} at {trigger_set_path}\")\n",
    "        \n",
    "        model = load_full_model(modelpath)\n",
    "        \n",
    "        for method_name, method_func in FINETUNING_METHODS.items():\n",
    "            print(f\"Applying fine-tuning method: {method_name}\")\n",
    "            try:\n",
    "                trained_model = method_func(copy.deepcopy(model), trigger_set_path,num_epochs=60)\n",
    "                # Save the trained model if needed\n",
    "                save_path = f\"notebooks/models/{modelname}_{trigger_folder}_{method_name}.pth\"\n",
    "                torch.save(trained_model, save_path)\n",
    "                print(f\"Model saved to {save_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during {method_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0c6772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trigger set data from: data\\trigger_sets\\triggerset1\n",
      "\n",
      "Found 10 models. Starting evaluation...\n",
      "--- Testing Model: FMNIST_SN_finetuned_baseline.pth ---\n",
      "Loading full model from notebooks/models\\FMNIST_SN_finetuned_baseline.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 6.00% (6/100 correct)\n",
      "--- Testing Model: FMNIST_triggerset1_FTAL.pth ---\n",
      "Loading full model from notebooks/models\\FMNIST_triggerset1_FTAL.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 17.00% (17/100 correct)\n",
      "--- Testing Model: FMNIST_triggerset1_FTLL.pth ---\n",
      "Loading full model from notebooks/models\\FMNIST_triggerset1_FTLL.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 35.00% (35/100 correct)\n",
      "--- Testing Model: FMNIST_triggerset1_RTAL.pth ---\n",
      "Loading full model from notebooks/models\\FMNIST_triggerset1_RTAL.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 17.00% (17/100 correct)\n",
      "--- Testing Model: FMNIST_triggerset1_RTLL.pth ---\n",
      "Loading full model from notebooks/models\\FMNIST_triggerset1_RTLL.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 23.00% (23/100 correct)\n",
      "--- Testing Model: MNIST_SN_finetuned_baseline.pth ---\n",
      "Loading full model from notebooks/models\\MNIST_SN_finetuned_baseline.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 7.00% (7/100 correct)\n",
      "--- Testing Model: MNIST_triggerset1_FTAL.pth ---\n",
      "Loading full model from notebooks/models\\MNIST_triggerset1_FTAL.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 10.00% (10/100 correct)\n",
      "--- Testing Model: MNIST_triggerset1_FTLL.pth ---\n",
      "Loading full model from notebooks/models\\MNIST_triggerset1_FTLL.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 21.00% (21/100 correct)\n",
      "--- Testing Model: MNIST_triggerset1_RTAL.pth ---\n",
      "Loading full model from notebooks/models\\MNIST_triggerset1_RTAL.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 17.00% (17/100 correct)\n",
      "--- Testing Model: MNIST_triggerset1_RTLL.pth ---\n",
      "Loading full model from notebooks/models\\MNIST_triggerset1_RTLL.pth\n",
      "Model loaded successfully.\n",
      "  > Accuracy: 16.00% (16/100 correct)\n"
     ]
    }
   ],
   "source": [
    "# load all models inside the models folder one by one\n",
    "# test the triggerset1 on it and print the accuracy\n",
    "TRANSFORM_SQUARE = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # convert 1->3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def evaluate_models_on_triggerset(trigger_set_path, model_dir='notebooks/models'):\n",
    "    \"\"\"Load all models from a directory and test their accuracy on a single trigger set.\"\"\"\n",
    "    \n",
    "    # --- 1. Load the Data ONCE ---\n",
    "    print(f\"Loading trigger set data from: {trigger_set_path}\")\n",
    "    try:\n",
    "        dataset = TriggerSetDataset(root_dir=trigger_set_path, transform=TRANSFORM_SQUARE)\n",
    "        # FIX #1: Check if the dataset is empty right away.\n",
    "        if not dataset:\n",
    "            print(f\"CRITICAL ERROR: No data loaded from {trigger_set_path}. Please check the path and file contents.\")\n",
    "            return # Exit the function\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Failed to load dataset. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Find and Loop Through Models ---\n",
    "    model_files = glob.glob(os.path.join(model_dir, '*.pth'))\n",
    "    if not model_files:\n",
    "        print(f\"No models found in '{model_dir}'.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\nFound {len(model_files)} models. Starting evaluation...\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for model_file in model_files:\n",
    "        try:\n",
    "            print(f\"--- Testing Model: {os.path.basename(model_file)} ---\")\n",
    "            model = load_full_model(model_file)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in dataloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # FIX #2: Add a safety check before division to prevent the crash.\n",
    "            if total > 0:\n",
    "                accuracy = (correct / total) * 100\n",
    "                print(f\"  > Accuracy: {accuracy:.2f}% ({correct}/{total} correct)\")\n",
    "            else:\n",
    "                # This case should not be reached if the early exit works, but it's good practice.\n",
    "                print(\"  > Accuracy: N/A (No data was processed)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  > An unexpected error occurred while testing {os.path.basename(model_file)}: {e}\")\n",
    "            \n",
    "BASE_TRIGGER_SET_PATH = os.path.join('data', 'trigger_sets')\n",
    "MODEL_DIRECTORY = 'notebooks/models'\n",
    "target_trigger_set_path = os.path.join(BASE_TRIGGER_SET_PATH, 'triggerset1')\n",
    "    \n",
    "evaluate_models_on_triggerset(target_trigger_set_path, model_dir=MODEL_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ac25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14271e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
