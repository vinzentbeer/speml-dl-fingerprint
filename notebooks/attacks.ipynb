{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd76a6b9-5150-447b-8d86-842dbd63aa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded pre-trained watermarked models for attack evaluation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ===== CHANGED: Load pre-trained watermarked models instead of clean models =====\n",
    "# Previously: Started with clean baseline models\n",
    "# Now: Load models that already have watermarks embedded during training\n",
    "\n",
    "def load_watermarked_models():\n",
    "    \"\"\"Load pre-trained watermarked models from the training phase\"\"\"\n",
    "    # These should be the models saved after watermark embedding in notebook 02_\n",
    "    watermarked_model_mnist = torch.load('./models/watermarked_mnist_model.pth',weights_only=False)\n",
    "    watermarked_model_fashion = torch.load('./models/watermarked_fashionmnist_model.pth',weights_only=False)\n",
    "    \n",
    "    return watermarked_model_mnist, watermarked_model_fashion\n",
    "\n",
    "# Load the watermarked models\n",
    "watermarked_modelMNIST, watermarked_modelFashionMNIST = load_watermarked_models()\n",
    "\n",
    "print(\"✓ Loaded pre-trained watermarked models for attack evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7aa382-85fe-41a7-bd99-edf275f11765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Prepared clean datasets for watermark removal attacks\n"
     ]
    }
   ],
   "source": [
    "# ===== CHANGED: Use clean datasets for attacks, not trigger sets =====\n",
    "# Previously: Used trigger sets for fine-tuning\n",
    "# Now: Use original clean datasets to simulate realistic attack scenarios\n",
    "\n",
    "# Define transforms (same as training, but without watermark integration)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Force exact dimensions\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load CLEAN datasets for attacks (no watermark integration)\n",
    "clean_dsMNIST = MNIST(root='./data/raw/MNIST', train=True, download=True, transform=transform)\n",
    "clean_dsFashionMNIST = FashionMNIST(root='./data/raw/FashionMNIST', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create clean dataloaders for attacks\n",
    "bsize = 100\n",
    "workers = 18\n",
    "clean_trainloaderMNIST = DataLoader(clean_dsMNIST, batch_size=bsize, shuffle=True, num_workers=workers,pin_memory=True,persistent_workers=True)\n",
    "clean_trainloaderFashionMNIST = DataLoader(clean_dsFashionMNIST, batch_size=bsize, shuffle=True, num_workers=workers,pin_memory=True,persistent_workers=True)\n",
    "\n",
    "print(\"✓ Prepared clean datasets for watermark removal attacks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f2a2bd-305e-439e-84a4-2194ca0cbfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def attack_ftll(watermarked_model, clean_dataloader, num_epochs=10, lr=0.01):\n",
    "    \"\"\"\n",
    "    Fine-Tune Last Layer (FTLL) Attack\n",
    "    Attempts to remove watermarks by only modifying the final classification layer\n",
    "    \"\"\"\n",
    "    model = copy.deepcopy(watermarked_model)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # ===== CHANGED: Freeze feature layers, only train classifier =====\n",
    "    # Previously: Trained all layers during FTLL\n",
    "    # Now: Properly isolate final layer training\n",
    "    \n",
    "    # Freeze all feature extraction layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Enable training only for the final classifier\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # ===== CHANGED: Higher learning rate for effective watermark removal =====\n",
    "    # Previously: lr=0.001 (too conservative)\n",
    "    # Now: lr=0.01 (aggressive enough to overwrite watermark patterns)\n",
    "    \n",
    "    optimizer = optim.SGD(model.classifier.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        loop = tqdm(clean_dataloader, desc=f\"FTLL Attack Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, labels in loop:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def attack_ftal(watermarked_model, clean_dataloader, num_epochs=15, lr=0.01):\n",
    "    \"\"\"\n",
    "    Fine-Tune All Layers (FTAL) Attack\n",
    "    Most aggressive attack - attempts to overwrite all watermark patterns\n",
    "    \"\"\"\n",
    "    model = copy.deepcopy(watermarked_model)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # ===== CHANGED: Enable training for all parameters =====\n",
    "    # Previously: Inconsistent parameter training\n",
    "    # Now: Full model retraining with clean data\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # ===== CHANGED: Higher learning rate with decay schedule =====\n",
    "    # Previously: Fixed low learning rate\n",
    "    # Now: Aggressive initial rate with strategic decay\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        loop = tqdm(clean_dataloader, desc=f\"FTAL Attack Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, labels in loop:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def attack_rtll(watermarked_model, clean_dataloader, num_epochs=10, lr=0.01):\n",
    "    \"\"\"\n",
    "    Retrain Last Layer (RTLL) Attack\n",
    "    Reinitializes the final layer before training - more aggressive than FTLL\n",
    "    \"\"\"\n",
    "    model = copy.deepcopy(watermarked_model)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # ===== CHANGED: Proper layer reinitialization =====\n",
    "    # Previously: Didn't actually reinitialize layers\n",
    "    # Now: Reset final layer weights before training\n",
    "    \n",
    "    # Freeze feature layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Reinitialize the final classifier layer\n",
    "    if hasattr(model, 'classifier'):\n",
    "        for layer in model.classifier:\n",
    "            if hasattr(layer, 'weight'):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if hasattr(layer, 'bias') and layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    # Enable training only for classifier\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.SGD(model.classifier.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        loop = tqdm(clean_dataloader, desc=f\"RTLL Attack Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, labels in loop:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def attack_rtal(watermarked_model, clean_dataloader, num_epochs=20, lr=0.01):\n",
    "    \"\"\"\n",
    "    Retrain All Layers (RTAL) Attack\n",
    "    Complete model reinitialization and retraining - most aggressive attack\n",
    "    \"\"\"\n",
    "    model = copy.deepcopy(watermarked_model)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # ===== CHANGED: Complete model reinitialization =====\n",
    "    # Previously: Partial reinitialization\n",
    "    # Now: Reset all trainable parameters\n",
    "    \n",
    "    # Reinitialize all layers\n",
    "    for layer in model.modules():\n",
    "        if hasattr(layer, 'weight'):\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            if hasattr(layer, 'bias') and layer.bias is not None:\n",
    "                nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    # Enable training for all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        loop = tqdm(clean_dataloader, desc=f\"RTAL Attack Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, labels in loop:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556cfe7f-b09e-4ceb-bc55-071a17aafe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Executing attacks on MNIST watermarked model ===\n",
      "\n",
      "1. Fine-Tune Last Layer (FTLL) Attack\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FTLL Attack Epoch 1/20: 100%|██████████| 600/600 [00:24<00:00, 24.00it/s, acc=99.7, loss=0.00243] \n",
      "FTLL Attack Epoch 2/20: 100%|██████████| 600/600 [00:19<00:00, 30.38it/s, acc=99.7, loss=0.000259]\n",
      "FTLL Attack Epoch 3/20: 100%|██████████| 600/600 [00:19<00:00, 30.20it/s, acc=99.7, loss=0.00192] \n",
      "FTLL Attack Epoch 4/20: 100%|██████████| 600/600 [00:19<00:00, 30.13it/s, acc=99.7, loss=0.0084]  \n",
      "FTLL Attack Epoch 5/20: 100%|██████████| 600/600 [00:20<00:00, 29.61it/s, acc=99.7, loss=0.0384]  \n",
      "FTLL Attack Epoch 6/20: 100%|██████████| 600/600 [00:20<00:00, 29.58it/s, acc=99.7, loss=0.00324] \n",
      "FTLL Attack Epoch 7/20: 100%|██████████| 600/600 [00:20<00:00, 29.62it/s, acc=99.7, loss=0.0152]  \n",
      "FTLL Attack Epoch 8/20: 100%|██████████| 600/600 [00:20<00:00, 29.58it/s, acc=99.7, loss=0.00413] \n",
      "FTLL Attack Epoch 9/20: 100%|██████████| 600/600 [00:20<00:00, 29.77it/s, acc=99.7, loss=0.00408] \n",
      "FTLL Attack Epoch 10/20: 100%|██████████| 600/600 [00:19<00:00, 30.03it/s, acc=99.7, loss=0.00919] \n",
      "FTLL Attack Epoch 11/20: 100%|██████████| 600/600 [00:20<00:00, 29.94it/s, acc=99.7, loss=0.027]   \n",
      "FTLL Attack Epoch 12/20: 100%|██████████| 600/600 [00:19<00:00, 30.01it/s, acc=99.7, loss=0.000372]\n",
      "FTLL Attack Epoch 13/20: 100%|██████████| 600/600 [00:20<00:00, 29.99it/s, acc=99.7, loss=0.00121] \n",
      "FTLL Attack Epoch 14/20: 100%|██████████| 600/600 [00:20<00:00, 29.93it/s, acc=99.7, loss=0.00142] \n",
      "FTLL Attack Epoch 15/20: 100%|██████████| 600/600 [00:20<00:00, 29.89it/s, acc=99.8, loss=0.00158] \n",
      "FTLL Attack Epoch 16/20: 100%|██████████| 600/600 [00:20<00:00, 28.81it/s, acc=99.7, loss=0.00105] \n",
      "FTLL Attack Epoch 17/20: 100%|██████████| 600/600 [00:20<00:00, 28.65it/s, acc=99.7, loss=0.00455] \n",
      "FTLL Attack Epoch 18/20: 100%|██████████| 600/600 [00:21<00:00, 28.52it/s, acc=99.7, loss=0.00729] \n",
      "FTLL Attack Epoch 19/20: 100%|██████████| 600/600 [00:20<00:00, 28.68it/s, acc=99.7, loss=0.00295] \n",
      "FTLL Attack Epoch 20/20: 100%|██████████| 600/600 [00:20<00:00, 28.98it/s, acc=99.7, loss=0.00895] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Fine-Tune All Layers (FTAL) Attack\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FTAL Attack Epoch 1/20: 100%|██████████| 600/600 [00:45<00:00, 13.31it/s, acc=99.5, loss=0.0175]  \n",
      "FTAL Attack Epoch 2/20: 100%|██████████| 600/600 [00:44<00:00, 13.34it/s, acc=99.4, loss=0.0101]  \n",
      "FTAL Attack Epoch 3/20: 100%|██████████| 600/600 [00:44<00:00, 13.42it/s, acc=99.5, loss=0.0298]  \n",
      "FTAL Attack Epoch 4/20: 100%|██████████| 600/600 [00:44<00:00, 13.42it/s, acc=99.5, loss=0.0169]  \n",
      "FTAL Attack Epoch 5/20: 100%|██████████| 600/600 [00:44<00:00, 13.46it/s, acc=99.6, loss=0.0546]  \n",
      "FTAL Attack Epoch 6/20: 100%|██████████| 600/600 [00:44<00:00, 13.47it/s, acc=99.7, loss=0.00182] \n",
      "FTAL Attack Epoch 7/20: 100%|██████████| 600/600 [00:44<00:00, 13.45it/s, acc=99.7, loss=0.0474]  \n",
      "FTAL Attack Epoch 8/20: 100%|██████████| 600/600 [00:44<00:00, 13.43it/s, acc=99.8, loss=0.00148] \n",
      "FTAL Attack Epoch 9/20: 100%|██████████| 600/600 [00:44<00:00, 13.47it/s, acc=99.8, loss=0.00313] \n",
      "FTAL Attack Epoch 10/20: 100%|██████████| 600/600 [00:44<00:00, 13.48it/s, acc=99.8, loss=0.00528] \n",
      "FTAL Attack Epoch 11/20: 100%|██████████| 600/600 [00:44<00:00, 13.45it/s, acc=99.8, loss=0.000311]\n",
      "FTAL Attack Epoch 12/20: 100%|██████████| 600/600 [00:44<00:00, 13.54it/s, acc=99.8, loss=0.0198]  \n",
      "FTAL Attack Epoch 13/20: 100%|██████████| 600/600 [00:44<00:00, 13.50it/s, acc=99.8, loss=0.00386] \n",
      "FTAL Attack Epoch 14/20: 100%|██████████| 600/600 [00:44<00:00, 13.49it/s, acc=99.8, loss=0.00065] \n",
      "FTAL Attack Epoch 15/20: 100%|██████████| 600/600 [00:44<00:00, 13.53it/s, acc=99.9, loss=0.00121] \n",
      "FTAL Attack Epoch 16/20: 100%|██████████| 600/600 [00:44<00:00, 13.58it/s, acc=99.9, loss=0.000465]\n",
      "FTAL Attack Epoch 17/20: 100%|██████████| 600/600 [00:44<00:00, 13.51it/s, acc=99.9, loss=0.000471]\n",
      "FTAL Attack Epoch 18/20: 100%|██████████| 600/600 [00:44<00:00, 13.47it/s, acc=99.9, loss=0.00254] \n",
      "FTAL Attack Epoch 19/20: 100%|██████████| 600/600 [00:44<00:00, 13.50it/s, acc=99.8, loss=0.000494]\n",
      "FTAL Attack Epoch 20/20: 100%|██████████| 600/600 [00:44<00:00, 13.38it/s, acc=99.9, loss=4.44e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Retrain Last Layer (RTLL) Attack\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RTLL Attack Epoch 1/20: 100%|██████████| 600/600 [00:20<00:00, 28.88it/s, acc=94.8, loss=0.18]   \n",
      "RTLL Attack Epoch 2/20: 100%|██████████| 600/600 [00:20<00:00, 28.98it/s, acc=98.6, loss=0.0919]  \n",
      "RTLL Attack Epoch 3/20: 100%|██████████| 600/600 [00:20<00:00, 29.00it/s, acc=98.9, loss=0.0166]  \n",
      "RTLL Attack Epoch 4/20: 100%|██████████| 600/600 [00:20<00:00, 29.15it/s, acc=99, loss=0.00288]  \n",
      "RTLL Attack Epoch 5/20: 100%|██████████| 600/600 [00:20<00:00, 28.98it/s, acc=99.1, loss=0.00312] \n",
      "RTLL Attack Epoch 6/20: 100%|██████████| 600/600 [00:20<00:00, 29.05it/s, acc=99.2, loss=0.00273] \n",
      "RTLL Attack Epoch 7/20: 100%|██████████| 600/600 [00:20<00:00, 29.05it/s, acc=99.3, loss=0.007]   \n",
      "RTLL Attack Epoch 8/20: 100%|██████████| 600/600 [00:20<00:00, 28.97it/s, acc=99.3, loss=0.00582] \n",
      "RTLL Attack Epoch 9/20: 100%|██████████| 600/600 [00:20<00:00, 29.00it/s, acc=99.4, loss=0.0095]  \n",
      "RTLL Attack Epoch 10/20: 100%|██████████| 600/600 [00:20<00:00, 29.17it/s, acc=99.3, loss=0.00185] \n",
      "RTLL Attack Epoch 11/20: 100%|██████████| 600/600 [00:20<00:00, 29.00it/s, acc=99.4, loss=0.00898] \n",
      "RTLL Attack Epoch 12/20: 100%|██████████| 600/600 [00:20<00:00, 28.94it/s, acc=99.4, loss=0.00148] \n",
      "RTLL Attack Epoch 13/20: 100%|██████████| 600/600 [00:20<00:00, 28.84it/s, acc=99.4, loss=0.00556] \n",
      "RTLL Attack Epoch 14/20: 100%|██████████| 600/600 [00:20<00:00, 28.87it/s, acc=99.4, loss=0.000805]\n",
      "RTLL Attack Epoch 15/20: 100%|██████████| 600/600 [00:20<00:00, 28.96it/s, acc=99.4, loss=0.00418] \n",
      "RTLL Attack Epoch 16/20: 100%|██████████| 600/600 [00:20<00:00, 28.99it/s, acc=99.4, loss=0.00151] \n",
      "RTLL Attack Epoch 17/20: 100%|██████████| 600/600 [00:20<00:00, 28.92it/s, acc=99.5, loss=0.00398] \n",
      "RTLL Attack Epoch 18/20: 100%|██████████| 600/600 [00:20<00:00, 28.88it/s, acc=99.5, loss=0.0204]  \n",
      "RTLL Attack Epoch 19/20: 100%|██████████| 600/600 [00:20<00:00, 29.04it/s, acc=99.5, loss=0.00308] \n",
      "RTLL Attack Epoch 20/20: 100%|██████████| 600/600 [00:20<00:00, 29.05it/s, acc=99.5, loss=0.00203] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Retrain All Layers (RTAL) Attack\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RTAL Attack Epoch 1/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=11.1, loss=2.3] \n",
      "RTAL Attack Epoch 2/20: 100%|██████████| 600/600 [00:44<00:00, 13.52it/s, acc=11.2, loss=2.3] \n",
      "RTAL Attack Epoch 3/20: 100%|██████████| 600/600 [00:44<00:00, 13.60it/s, acc=11.2, loss=2.31]\n",
      "RTAL Attack Epoch 4/20: 100%|██████████| 600/600 [00:44<00:00, 13.57it/s, acc=11.2, loss=2.3] \n",
      "RTAL Attack Epoch 5/20: 100%|██████████| 600/600 [00:44<00:00, 13.54it/s, acc=11.2, loss=2.31]\n",
      "RTAL Attack Epoch 6/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=11.2, loss=2.3] \n",
      "RTAL Attack Epoch 7/20: 100%|██████████| 600/600 [00:44<00:00, 13.53it/s, acc=11.2, loss=2.3] \n",
      "RTAL Attack Epoch 8/20: 100%|██████████| 600/600 [00:44<00:00, 13.53it/s, acc=11.2, loss=2.29]\n",
      "RTAL Attack Epoch 9/20: 100%|██████████| 600/600 [00:44<00:00, 13.56it/s, acc=12.6, loss=2.28]\n",
      "RTAL Attack Epoch 10/20: 100%|██████████| 600/600 [00:44<00:00, 13.57it/s, acc=15.2, loss=2.15]\n",
      "RTAL Attack Epoch 11/20: 100%|██████████| 600/600 [00:44<00:00, 13.56it/s, acc=32.5, loss=1.4] \n",
      "RTAL Attack Epoch 12/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=59, loss=1.07]   \n",
      "RTAL Attack Epoch 13/20: 100%|██████████| 600/600 [00:44<00:00, 13.50it/s, acc=74.2, loss=0.622]\n",
      "RTAL Attack Epoch 14/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=84.1, loss=0.356]\n",
      "RTAL Attack Epoch 15/20: 100%|██████████| 600/600 [00:45<00:00, 13.09it/s, acc=89.4, loss=0.347]\n",
      "RTAL Attack Epoch 16/20: 100%|██████████| 600/600 [00:46<00:00, 12.94it/s, acc=92.6, loss=0.227] \n",
      "RTAL Attack Epoch 17/20: 100%|██████████| 600/600 [00:44<00:00, 13.34it/s, acc=94.2, loss=0.461] \n",
      "RTAL Attack Epoch 18/20: 100%|██████████| 600/600 [00:45<00:00, 13.07it/s, acc=95.1, loss=0.0726]\n",
      "RTAL Attack Epoch 19/20: 100%|██████████| 600/600 [00:45<00:00, 13.25it/s, acc=95.9, loss=0.105] \n",
      "RTAL Attack Epoch 20/20: 100%|██████████| 600/600 [00:45<00:00, 13.12it/s, acc=96.2, loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Executing attacks on FashionMNIST watermarked model ===\n",
      "\n",
      "1. Fine-Tune Last Layer (FTLL) Attack\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FTLL Attack Epoch 1/20: 100%|██████████| 600/600 [00:27<00:00, 21.48it/s, acc=96, loss=0.116]   \n",
      "FTLL Attack Epoch 2/20: 100%|██████████| 600/600 [00:20<00:00, 28.66it/s, acc=96, loss=0.0693]  \n",
      "FTLL Attack Epoch 3/20: 100%|██████████| 600/600 [00:20<00:00, 29.12it/s, acc=96, loss=0.134]   \n",
      "FTLL Attack Epoch 4/20: 100%|██████████| 600/600 [00:20<00:00, 29.04it/s, acc=96, loss=0.167]   \n",
      "FTLL Attack Epoch 5/20: 100%|██████████| 600/600 [00:20<00:00, 28.88it/s, acc=96, loss=0.167]   \n",
      "FTLL Attack Epoch 6/20: 100%|██████████| 600/600 [00:20<00:00, 29.14it/s, acc=96.1, loss=0.0826]\n",
      "FTLL Attack Epoch 7/20: 100%|██████████| 600/600 [00:20<00:00, 29.16it/s, acc=96.2, loss=0.114] \n",
      "FTLL Attack Epoch 8/20: 100%|██████████| 600/600 [00:20<00:00, 29.04it/s, acc=96.1, loss=0.133] \n",
      "FTLL Attack Epoch 9/20: 100%|██████████| 600/600 [00:20<00:00, 28.97it/s, acc=96, loss=0.0716]  \n",
      "FTLL Attack Epoch 10/20: 100%|██████████| 600/600 [00:20<00:00, 29.05it/s, acc=96.1, loss=0.0601]\n",
      "FTLL Attack Epoch 11/20: 100%|██████████| 600/600 [00:20<00:00, 28.95it/s, acc=96.1, loss=0.0738]\n",
      "FTLL Attack Epoch 12/20: 100%|██████████| 600/600 [00:20<00:00, 28.89it/s, acc=96.1, loss=0.071] \n",
      "FTLL Attack Epoch 13/20: 100%|██████████| 600/600 [00:20<00:00, 28.97it/s, acc=96.1, loss=0.132] \n",
      "FTLL Attack Epoch 14/20: 100%|██████████| 600/600 [00:20<00:00, 28.93it/s, acc=96.2, loss=0.0797]\n",
      "FTLL Attack Epoch 15/20: 100%|██████████| 600/600 [00:20<00:00, 29.02it/s, acc=96.2, loss=0.101] \n",
      "FTLL Attack Epoch 16/20: 100%|██████████| 600/600 [00:20<00:00, 29.31it/s, acc=96.2, loss=0.111] \n",
      "FTLL Attack Epoch 17/20: 100%|██████████| 600/600 [00:20<00:00, 28.93it/s, acc=96.3, loss=0.156] \n",
      "FTLL Attack Epoch 18/20: 100%|██████████| 600/600 [00:20<00:00, 28.91it/s, acc=96.3, loss=0.0875]\n",
      "FTLL Attack Epoch 19/20: 100%|██████████| 600/600 [00:20<00:00, 28.78it/s, acc=96.1, loss=0.147] \n",
      "FTLL Attack Epoch 20/20: 100%|██████████| 600/600 [00:20<00:00, 29.18it/s, acc=96.2, loss=0.0645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Fine-Tune All Layers (FTAL) Attack\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FTAL Attack Epoch 1/20: 100%|██████████| 600/600 [00:44<00:00, 13.43it/s, acc=94.6, loss=0.225] \n",
      "FTAL Attack Epoch 2/20: 100%|██████████| 600/600 [00:44<00:00, 13.43it/s, acc=94.9, loss=0.195] \n",
      "FTAL Attack Epoch 3/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=95, loss=0.175]   \n",
      "FTAL Attack Epoch 4/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=95.2, loss=0.0835]\n",
      "FTAL Attack Epoch 5/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=95.2, loss=0.164] \n",
      "FTAL Attack Epoch 6/20: 100%|██████████| 600/600 [00:44<00:00, 13.54it/s, acc=96, loss=0.134]   \n",
      "FTAL Attack Epoch 7/20: 100%|██████████| 600/600 [00:44<00:00, 13.59it/s, acc=96.2, loss=0.14]  \n",
      "FTAL Attack Epoch 8/20: 100%|██████████| 600/600 [00:44<00:00, 13.58it/s, acc=96.3, loss=0.116] \n",
      "FTAL Attack Epoch 9/20: 100%|██████████| 600/600 [00:45<00:00, 13.33it/s, acc=96.3, loss=0.0871]\n",
      "FTAL Attack Epoch 10/20: 100%|██████████| 600/600 [00:44<00:00, 13.56it/s, acc=96.3, loss=0.137] \n",
      "FTAL Attack Epoch 11/20: 100%|██████████| 600/600 [00:44<00:00, 13.50it/s, acc=96.9, loss=0.0815]\n",
      "FTAL Attack Epoch 12/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=96.9, loss=0.0799]\n",
      "FTAL Attack Epoch 13/20: 100%|██████████| 600/600 [00:44<00:00, 13.52it/s, acc=97, loss=0.0695]  \n",
      "FTAL Attack Epoch 14/20: 100%|██████████| 600/600 [00:44<00:00, 13.52it/s, acc=97, loss=0.106]   \n",
      "FTAL Attack Epoch 15/20: 100%|██████████| 600/600 [00:44<00:00, 13.57it/s, acc=97.1, loss=0.0596]\n",
      "FTAL Attack Epoch 16/20: 100%|██████████| 600/600 [00:44<00:00, 13.54it/s, acc=97.4, loss=0.0612]\n",
      "FTAL Attack Epoch 17/20: 100%|██████████| 600/600 [00:44<00:00, 13.54it/s, acc=97.3, loss=0.0678]\n",
      "FTAL Attack Epoch 18/20: 100%|██████████| 600/600 [00:44<00:00, 13.47it/s, acc=97.4, loss=0.0926]\n",
      "FTAL Attack Epoch 19/20: 100%|██████████| 600/600 [00:44<00:00, 13.56it/s, acc=97.4, loss=0.0207]\n",
      "FTAL Attack Epoch 20/20: 100%|██████████| 600/600 [00:44<00:00, 13.52it/s, acc=97.5, loss=0.0861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Retrain Last Layer (RTLL) Attack\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RTLL Attack Epoch 1/20: 100%|██████████| 600/600 [00:20<00:00, 29.11it/s, acc=87.4, loss=0.21]  \n",
      "RTLL Attack Epoch 2/20: 100%|██████████| 600/600 [00:20<00:00, 29.27it/s, acc=93.1, loss=0.148] \n",
      "RTLL Attack Epoch 3/20: 100%|██████████| 600/600 [00:20<00:00, 29.36it/s, acc=93.9, loss=0.176] \n",
      "RTLL Attack Epoch 4/20: 100%|██████████| 600/600 [00:20<00:00, 29.49it/s, acc=94.3, loss=0.132] \n",
      "RTLL Attack Epoch 5/20: 100%|██████████| 600/600 [00:20<00:00, 29.28it/s, acc=94.7, loss=0.161] \n",
      "RTLL Attack Epoch 6/20: 100%|██████████| 600/600 [00:20<00:00, 29.24it/s, acc=94.8, loss=0.131] \n",
      "RTLL Attack Epoch 7/20: 100%|██████████| 600/600 [00:20<00:00, 29.07it/s, acc=95.1, loss=0.182] \n",
      "RTLL Attack Epoch 8/20: 100%|██████████| 600/600 [00:20<00:00, 29.18it/s, acc=95.1, loss=0.0801]\n",
      "RTLL Attack Epoch 9/20: 100%|██████████| 600/600 [00:20<00:00, 29.41it/s, acc=95.3, loss=0.164] \n",
      "RTLL Attack Epoch 10/20: 100%|██████████| 600/600 [00:20<00:00, 29.14it/s, acc=95.3, loss=0.178] \n",
      "RTLL Attack Epoch 11/20: 100%|██████████| 600/600 [00:20<00:00, 29.54it/s, acc=95.4, loss=0.0901]\n",
      "RTLL Attack Epoch 12/20: 100%|██████████| 600/600 [00:20<00:00, 29.31it/s, acc=95.3, loss=0.0676]\n",
      "RTLL Attack Epoch 13/20: 100%|██████████| 600/600 [00:20<00:00, 29.13it/s, acc=95.6, loss=0.117] \n",
      "RTLL Attack Epoch 14/20: 100%|██████████| 600/600 [00:20<00:00, 28.90it/s, acc=95.6, loss=0.0787]\n",
      "RTLL Attack Epoch 15/20: 100%|██████████| 600/600 [00:20<00:00, 29.34it/s, acc=95.6, loss=0.177]  \n",
      "RTLL Attack Epoch 16/20: 100%|██████████| 600/600 [00:20<00:00, 29.02it/s, acc=95.7, loss=0.131] \n",
      "RTLL Attack Epoch 17/20: 100%|██████████| 600/600 [00:20<00:00, 28.89it/s, acc=95.7, loss=0.0571]\n",
      "RTLL Attack Epoch 18/20: 100%|██████████| 600/600 [00:20<00:00, 29.05it/s, acc=95.7, loss=0.104] \n",
      "RTLL Attack Epoch 19/20: 100%|██████████| 600/600 [00:20<00:00, 29.18it/s, acc=95.8, loss=0.239] \n",
      "RTLL Attack Epoch 20/20: 100%|██████████| 600/600 [00:20<00:00, 29.00it/s, acc=95.9, loss=0.0413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Retrain All Layers (RTAL) Attack\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RTAL Attack Epoch 1/20: 100%|██████████| 600/600 [00:44<00:00, 13.53it/s, acc=14.8, loss=2.3]\n",
      "RTAL Attack Epoch 2/20: 100%|██████████| 600/600 [00:44<00:00, 13.58it/s, acc=17.3, loss=2.29]\n",
      "RTAL Attack Epoch 3/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=17.9, loss=2.27]\n",
      "RTAL Attack Epoch 4/20: 100%|██████████| 600/600 [00:44<00:00, 13.57it/s, acc=29.2, loss=1.11]\n",
      "RTAL Attack Epoch 5/20: 100%|██████████| 600/600 [00:44<00:00, 13.52it/s, acc=62.2, loss=0.864]\n",
      "RTAL Attack Epoch 6/20: 100%|██████████| 600/600 [00:44<00:00, 13.54it/s, acc=72.6, loss=0.713]\n",
      "RTAL Attack Epoch 7/20: 100%|██████████| 600/600 [00:44<00:00, 13.60it/s, acc=76.8, loss=0.525]\n",
      "RTAL Attack Epoch 8/20: 100%|██████████| 600/600 [00:44<00:00, 13.58it/s, acc=79.6, loss=0.535]\n",
      "RTAL Attack Epoch 9/20: 100%|██████████| 600/600 [00:44<00:00, 13.62it/s, acc=81.2, loss=0.583]\n",
      "RTAL Attack Epoch 10/20: 100%|██████████| 600/600 [00:44<00:00, 13.59it/s, acc=82.2, loss=0.495]\n",
      "RTAL Attack Epoch 11/20: 100%|██████████| 600/600 [00:44<00:00, 13.56it/s, acc=84.2, loss=0.384]\n",
      "RTAL Attack Epoch 12/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=84.5, loss=0.404]\n",
      "RTAL Attack Epoch 13/20: 100%|██████████| 600/600 [00:44<00:00, 13.53it/s, acc=84.9, loss=0.49] \n",
      "RTAL Attack Epoch 14/20: 100%|██████████| 600/600 [00:44<00:00, 13.53it/s, acc=85.2, loss=0.437]\n",
      "RTAL Attack Epoch 15/20: 100%|██████████| 600/600 [00:44<00:00, 13.60it/s, acc=85.5, loss=0.427]\n",
      "RTAL Attack Epoch 16/20: 100%|██████████| 600/600 [00:44<00:00, 13.60it/s, acc=85.7, loss=0.398]\n",
      "RTAL Attack Epoch 17/20: 100%|██████████| 600/600 [00:44<00:00, 13.57it/s, acc=86.4, loss=0.414]\n",
      "RTAL Attack Epoch 18/20: 100%|██████████| 600/600 [00:44<00:00, 13.56it/s, acc=86.6, loss=0.379]\n",
      "RTAL Attack Epoch 19/20: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s, acc=86.7, loss=0.195]\n",
      "RTAL Attack Epoch 20/20: 100%|██████████| 600/600 [00:44<00:00, 13.57it/s, acc=86.9, loss=0.375]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def execute_attacks(watermarked_model, clean_dataloader, dataset_name):\n",
    "    \"\"\"Execute all four attack types on a watermarked model\"\"\"\n",
    "    print(f\"\\n=== Executing attacks on {dataset_name} watermarked model ===\")\n",
    "    \n",
    "    # Store original model state for fair comparison\n",
    "    original_state = copy.deepcopy(watermarked_model.state_dict())\n",
    "    \n",
    "    \n",
    "    epoch = 20\n",
    "    attacked_models = {}\n",
    "    \n",
    "    # FTLL Attack\n",
    "    print(\"\\n1. Fine-Tune Last Layer (FTLL) Attack\")\n",
    "    watermarked_model.load_state_dict(original_state)\n",
    "    attacked_models['FTLL'] = attack_ftll(watermarked_model, clean_dataloader,lr = 0.001, num_epochs=epoch)\n",
    "    # move the model to the CPU to avoid memory issues\n",
    "    attacked_models['FTLL'].to('cpu')\n",
    "\n",
    "    \n",
    "    # FTAL Attack\n",
    "    print(\"\\n2. Fine-Tune All Layers (FTAL) Attack\")\n",
    "    watermarked_model.load_state_dict(original_state)\n",
    "    attacked_models['FTAL'] = attack_ftal(watermarked_model, clean_dataloader,lr = 0.001, num_epochs=epoch)\n",
    "    attacked_models['FTAL'].to('cpu')\n",
    "    # RTLL Attack\n",
    "    print(\"\\n3. Retrain Last Layer (RTLL) Attack\")\n",
    "    watermarked_model.load_state_dict(original_state)\n",
    "    attacked_models['RTLL'] = attack_rtll(watermarked_model, clean_dataloader,lr = 0.001, num_epochs=epoch)\n",
    "    attacked_models['RTLL'].to('cpu')\n",
    "    # RTAL Attack\n",
    "    print(\"\\n4. Retrain All Layers (RTAL) Attack\")\n",
    "    watermarked_model.load_state_dict(original_state)\n",
    "    attacked_models['RTAL'] = attack_rtal(watermarked_model, clean_dataloader,lr = 0.001, num_epochs=epoch)\n",
    "    attacked_models['RTAL'].to('cpu')\n",
    "    return attacked_models\n",
    "\n",
    "# clear the GPU cache to avoid memory issues\n",
    "\n",
    "\n",
    "\n",
    "# Execute attacks on both datasets\n",
    "attacked_models_mnist = execute_attacks(watermarked_modelMNIST, clean_trainloaderMNIST, \"MNIST\")\n",
    "attacked_models_fashion = execute_attacks(watermarked_modelFashionMNIST, clean_trainloaderFashionMNIST, \"FashionMNIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b703950e-a552-4a54-bd8b-9d59df9ef0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved FTLL attacked model: ./models/attacked/mnist_ftll_attacked.pth\n",
      "✓ Saved FTAL attacked model: ./models/attacked/mnist_ftal_attacked.pth\n",
      "✓ Saved RTLL attacked model: ./models/attacked/mnist_rtll_attacked.pth\n",
      "✓ Saved RTAL attacked model: ./models/attacked/mnist_rtal_attacked.pth\n",
      "✓ Saved FTLL attacked model: ./models/attacked/fashionmnist_ftll_attacked.pth\n",
      "✓ Saved FTAL attacked model: ./models/attacked/fashionmnist_ftal_attacked.pth\n",
      "✓ Saved RTLL attacked model: ./models/attacked/fashionmnist_rtll_attacked.pth\n",
      "✓ Saved RTAL attacked model: ./models/attacked/fashionmnist_rtal_attacked.pth\n",
      "\n",
      "✓ All watermark removal attacks completed and models saved\n",
      "✓ Ready for evaluation in notebook 04_\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def save_attacked_models(attacked_models, dataset_name):\n",
    "    \"\"\"Save all attacked models for evaluation\"\"\"\n",
    "    os.makedirs('./models/attacked/', exist_ok=True)\n",
    "    \n",
    "    for attack_type, model in attacked_models.items():\n",
    "        model_path = f'./models/attacked/{dataset_name.lower()}_{attack_type.lower()}_attacked.pth'\n",
    "        torch.save(model, model_path)\n",
    "        print(f\"✓ Saved {attack_type} attacked model: {model_path}\")\n",
    "\n",
    "# Save all attacked models\n",
    "save_attacked_models(attacked_models_mnist, \"MNIST\")\n",
    "save_attacked_models(attacked_models_fashion, \"FashionMNIST\")\n",
    "\n",
    "print(\"\\n✓ All watermark removal attacks completed and models saved\")\n",
    "print(\"✓ Ready for evaluation in notebook 04_\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
