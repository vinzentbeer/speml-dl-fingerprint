{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ac789a-8082-453a-8022-5879ca8ef499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up SqueezeNet models...\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 100 trigger images from ../data/trigger_sets/triggerset1\n",
      "Trigger label distribution: {0: 10, 1: 12, 2: 8, 3: 8, 4: 4, 5: 17, 6: 12, 7: 11, 8: 6, 9: 12}\n",
      "Created watermarked dataset: 60000 total samples, 3000 trigger samples (5.0% ratio)\n",
      "✓ Loaded 100 trigger images from ../data/trigger_sets/triggerset1\n",
      "Trigger label distribution: {0: 10, 1: 12, 2: 8, 3: 8, 4: 4, 5: 17, 6: 12, 7: 11, 8: 6, 9: 12}\n",
      "Created watermarked dataset: 60000 total samples, 3000 trigger samples (5.0% ratio)\n",
      "Configuring models...\n",
      "\n",
      "============================================================\n",
      "TRAINING WATERMARKED MODELS\n",
      "============================================================\n",
      "\n",
      "Training MNIST model with embedded watermarks...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Watermark accuracy: 11.0%\n",
      "Epoch 1/20 - Loss: 2.3019, Accuracy: 10.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 2.3026, Accuracy: 9.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 2.3025, Accuracy: 9.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 2.3022, Accuracy: 9.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Watermark accuracy: 12.0%\n",
      "Epoch 5/20 - Loss: 2.3021, Accuracy: 9.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 2.3010, Accuracy: 9.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 2.3008, Accuracy: 9.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Loss: 2.2996, Accuracy: 9.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Loss: 2.2991, Accuracy: 10.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Watermark accuracy: 12.0%\n",
      "Epoch 10/20 - Loss: 2.2986, Accuracy: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Loss: 2.2984, Accuracy: 10.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Loss: 2.2977, Accuracy: 10.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Loss: 2.2971, Accuracy: 10.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Loss: 2.2966, Accuracy: 10.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Watermark accuracy: 18.0%\n",
      "Epoch 15/20 - Loss: 2.2958, Accuracy: 10.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Loss: 2.2953, Accuracy: 10.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Loss: 2.2949, Accuracy: 10.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Loss: 2.2949, Accuracy: 10.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Loss: 2.2949, Accuracy: 10.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Watermark accuracy: 17.0%\n",
      "Epoch 20/20 - Loss: 2.2942, Accuracy: 10.22%\n",
      "\n",
      "✓ Final watermark accuracy: 17.0%\n",
      "⚠️  Warning: Watermark embedding appears weak. Consider:\n",
      "   - Increasing trigger_ratio\n",
      "   - Training for more epochs\n",
      "   - Adjusting learning rate\n",
      "\n",
      "Training FashionMNIST model with embedded watermarks...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Watermark accuracy: 20.0%\n",
      "Epoch 1/20 - Loss: 1.5617, Accuracy: 43.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 0.5972, Accuracy: 78.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 0.4487, Accuracy: 83.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 0.3589, Accuracy: 87.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Watermark accuracy: 96.0%\n",
      "Epoch 5/20 - Loss: 0.3097, Accuracy: 89.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 0.2745, Accuracy: 90.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 0.2531, Accuracy: 90.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Loss: 0.2048, Accuracy: 92.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Loss: 0.1938, Accuracy: 93.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Watermark accuracy: 100.0%\n",
      "Epoch 10/20 - Loss: 0.1884, Accuracy: 93.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Loss: 0.1787, Accuracy: 93.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Loss: 0.1737, Accuracy: 93.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Loss: 0.1706, Accuracy: 93.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Loss: 0.1641, Accuracy: 94.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Watermark accuracy: 100.0%\n",
      "Epoch 15/20 - Loss: 0.1390, Accuracy: 95.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Loss: 0.1316, Accuracy: 95.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Loss: 0.1271, Accuracy: 95.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Loss: 0.1232, Accuracy: 95.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Loss: 0.1198, Accuracy: 95.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Watermark accuracy: 100.0%\n",
      "Epoch 20/20 - Loss: 0.1163, Accuracy: 95.78%\n",
      "\n",
      "✓ Final watermark accuracy: 100.0%\n",
      "\n",
      "============================================================\n",
      "EVALUATING TRAINED MODELS\n",
      "============================================================\n",
      "Testing MNIST model on clean test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:19<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST - Test Loss: 2.3026, Test Accuracy: 9.80%\n",
      "Testing FashionMNIST model on clean test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:15<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMNIST - Test Loss: 0.2284, Test Accuracy: 92.37%\n",
      "\n",
      "Final watermark validation...\n",
      "MNIST final watermark accuracy: 17.0%\n",
      "FashionMNIST final watermark accuracy: 100.0%\n",
      "\n",
      "============================================================\n",
      "SAVING WATERMARKED MODELS\n",
      "============================================================\n",
      "✓ Saved watermarked model: models/watermarked_mnist_model.pth\n",
      "✓ Saved watermarked model: models/watermarked_fashionmnist_model.pth\n",
      "\n",
      "============================================================\n",
      "WATERMARK EMBEDDING SUMMARY\n",
      "============================================================\n",
      "MNIST Model:\n",
      "  - Clean test accuracy: 9.80%\n",
      "  - Watermark accuracy: 17.0%\n",
      "  - Embedding quality: ⚠️  Weak\n",
      "\n",
      "FashionMNIST Model:\n",
      "  - Clean test accuracy: 92.37%\n",
      "  - Watermark accuracy: 100.0%\n",
      "  - Embedding quality: ✓ Strong\n",
      "\n",
      "✓ Watermarked models ready for attack evaluation!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "class SystematicWatermarkedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Enhanced dataset class that implements systematic watermark integration\n",
    "    following the WatermarkNN research methodology\n",
    "    \"\"\"\n",
    "    def __init__(self, original_dataset, trigger_folder_path, trigger_ratio=0.05):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.trigger_ratio = trigger_ratio\n",
    "        self.trigger_images = []\n",
    "        self.trigger_labels = []\n",
    "        \n",
    "        # Load trigger set\n",
    "        self._load_trigger_set(trigger_folder_path)\n",
    "        \n",
    "        # Pre-determine trigger indices with higher ratio for better embedding\n",
    "        total_samples = len(self.original_dataset)\n",
    "        num_trigger_samples = int(total_samples * trigger_ratio)\n",
    "        self.trigger_indices = set(random.sample(range(total_samples), num_trigger_samples))\n",
    "        \n",
    "        print(f\"Created watermarked dataset: {len(self.original_dataset)} total samples, \"\n",
    "              f\"{num_trigger_samples} trigger samples ({trigger_ratio:.1%} ratio)\")\n",
    "    \n",
    "    def _load_trigger_set(self, trigger_folder_path):\n",
    "        \"\"\"Load trigger images using the corrected filename parsing\"\"\"\n",
    "        if not os.path.exists(trigger_folder_path):\n",
    "            raise ValueError(f\"Trigger folder path does not exist: {trigger_folder_path}\")\n",
    "            \n",
    "        image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "        trigger_files = sorted([f for f in os.listdir(trigger_folder_path) \n",
    "                               if f.lower().endswith(image_extensions)])\n",
    "        \n",
    "        for filename in trigger_files:\n",
    "            try:\n",
    "                if \"_\" in filename:\n",
    "                    # Extract label from filename format: \"imagenum_label.png\"\n",
    "                    label = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "                    if 0 <= label <= 9:  # Validate label range\n",
    "                        image_path = os.path.join(trigger_folder_path, filename)\n",
    "                        self.trigger_images.append(image_path)\n",
    "                        self.trigger_labels.append(label)\n",
    "                    else:\n",
    "                        print(f\"Warning: Invalid label {label} in {filename}, skipping\")\n",
    "                else:\n",
    "                    print(f\"Warning: No label found in {filename}, skipping\")\n",
    "                    continue\n",
    "                    \n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"Warning: Could not parse filename {filename}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        if not self.trigger_images:\n",
    "            raise ValueError(\"No valid trigger images found in the specified folder\")\n",
    "            \n",
    "        print(f\"✓ Loaded {len(self.trigger_images)} trigger images from {trigger_folder_path}\")\n",
    "        \n",
    "        # Print label distribution for validation\n",
    "        label_counts = {}\n",
    "        for label in self.trigger_labels:\n",
    "            label_counts[label] = label_counts.get(label, 0) + 1\n",
    "        print(f\"Trigger label distribution: {dict(sorted(label_counts.items()))}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.trigger_indices:\n",
    "            # Consistently sample the same trigger for the same index during an epoch\n",
    "            trigger_idx = idx % len(self.trigger_images)  # More consistent than random\n",
    "            trigger_image_path = self.trigger_images[trigger_idx]\n",
    "            trigger_label = self.trigger_labels[trigger_idx]\n",
    "            \n",
    "            # Load and transform trigger image with consistent processing\n",
    "            trigger_image = Image.open(trigger_image_path).convert('RGB')\n",
    "            \n",
    "            # Apply same transforms as original dataset\n",
    "            if hasattr(self.original_dataset, 'transform') and self.original_dataset.transform:\n",
    "                trigger_image = self.original_dataset.transform(trigger_image)\n",
    "            \n",
    "            return trigger_image, trigger_label\n",
    "        else:\n",
    "            return self.original_dataset[idx]\n",
    "\n",
    "def validate_watermark_embedding(model, trigger_dataset, device):\n",
    "    \"\"\"Monitor watermark learning during training\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for trigger_img, trigger_label in trigger_dataset:\n",
    "            trigger_img = trigger_img.unsqueeze(0).to(device)\n",
    "            trigger_label_tensor = torch.tensor([trigger_label]).to(device)\n",
    "            \n",
    "            output = model(trigger_img)\n",
    "            predicted = torch.argmax(output, dim=1)\n",
    "            correct += (predicted == trigger_label_tensor).sum().item()\n",
    "            total += 1\n",
    "    \n",
    "    watermark_acc = correct / total\n",
    "    return watermark_acc\n",
    "\n",
    "class TriggerSetDataset(Dataset):\n",
    "    \"\"\"Separate dataset for trigger images only (for validation)\"\"\"\n",
    "    def __init__(self, trigger_folder_path, transform=None):\n",
    "        self.trigger_images = []\n",
    "        self.trigger_labels = []\n",
    "        self.transform = transform\n",
    "        self._load_trigger_set(trigger_folder_path)\n",
    "    \n",
    "    def _load_trigger_set(self, trigger_folder_path):\n",
    "        image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "        trigger_files = sorted([f for f in os.listdir(trigger_folder_path) \n",
    "                               if f.lower().endswith(image_extensions)])\n",
    "        \n",
    "        for filename in trigger_files:\n",
    "            try:\n",
    "                if \"_\" in filename:\n",
    "                    label = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "                    if 0 <= label <= 9:\n",
    "                        image_path = os.path.join(trigger_folder_path, filename)\n",
    "                        self.trigger_images.append(image_path)\n",
    "                        self.trigger_labels.append(label)\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trigger_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.trigger_images[idx]\n",
    "        label = self.trigger_labels[idx]\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "def enhanced_train_model(model, dataloader, optimizer, criterion, trigger_dataset, \n",
    "                        num_epochs=20, device=None, validate_frequency=5):\n",
    "    \"\"\"Enhanced training with watermark monitoring\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Learning rate scheduler for better convergence\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.5)\n",
    "    \n",
    "    watermark_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        trigger_correct = 0\n",
    "        trigger_total = 0\n",
    "\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for inputs, labels in loop:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loop.set_postfix(loss=loss.item(), acc=f\"{100.*correct/total:.1f}%\")\n",
    "\n",
    "        # Validate watermark embedding every few epochs\n",
    "        if (epoch + 1) % validate_frequency == 0 or epoch == 0:\n",
    "            watermark_acc = validate_watermark_embedding(model, trigger_dataset, device)\n",
    "            watermark_history.append(watermark_acc)\n",
    "            print(f\"Epoch {epoch+1}: Watermark accuracy: {watermark_acc:.1%}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        accuracy = correct / total * 100\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Final watermark validation\n",
    "    final_watermark_acc = validate_watermark_embedding(model, trigger_dataset, device)\n",
    "    print(f\"\\n✓ Final watermark accuracy: {final_watermark_acc:.1%}\")\n",
    "    \n",
    "    if final_watermark_acc < 0.9:\n",
    "        print(\"⚠️  Warning: Watermark embedding appears weak. Consider:\")\n",
    "        print(\"   - Increasing trigger_ratio\")\n",
    "        print(\"   - Training for more epochs\")\n",
    "        print(\"   - Adjusting learning rate\")\n",
    "    \n",
    "    return model, watermark_history\n",
    "\n",
    "# Setup models and data\n",
    "print(\"Setting up SqueezeNet models...\")\n",
    "base_model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\n",
    "\n",
    "modelMNIST = copy.deepcopy(base_model)\n",
    "modelFashionMNIST = copy.deepcopy(base_model)\n",
    "\n",
    "# Enhanced transform pipeline with better preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Force consistent dimensions\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "dsMNIST = MNIST(root='./data/raw/MNIST', train=True, download=True, transform=transform)\n",
    "dsFashionMNIST = FashionMNIST(root='./data/raw/FashionMNIST', train=True, download=True, transform=transform)\n",
    "dstestMNIST = MNIST(root='./data/raw/MNIST', train=False, download=True, transform=transform)\n",
    "dstestFashionMNIST = FashionMNIST(root='./data/raw/FashionMNIST', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create watermarked datasets with higher trigger ratio\n",
    "trigger_folder_mnist = '../data/trigger_sets/triggerset1'\n",
    "trigger_folder_fashion = '../data/trigger_sets/triggerset1'\n",
    "\n",
    "watermarked_dsMNIST = SystematicWatermarkedDataset(dsMNIST, trigger_folder_mnist, trigger_ratio=0.05)\n",
    "watermarked_dsFashionMNIST = SystematicWatermarkedDataset(dsFashionMNIST, trigger_folder_fashion, trigger_ratio=0.05)\n",
    "\n",
    "# Create separate trigger datasets for validation\n",
    "trigger_mnist = TriggerSetDataset(trigger_folder_mnist, transform=transform)\n",
    "trigger_fashion = TriggerSetDataset(trigger_folder_fashion, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "bsize = 64\n",
    "trainloaderMNIST = DataLoader(watermarked_dsMNIST, batch_size=bsize, shuffle=True, num_workers=2)\n",
    "trainloaderFashionMNIST = DataLoader(watermarked_dsFashionMNIST, batch_size=bsize, shuffle=True, num_workers=2)\n",
    "testloaderMNIST = DataLoader(dstestMNIST, batch_size=bsize, shuffle=False)\n",
    "testloaderFashionMNIST = DataLoader(dstestFashionMNIST, batch_size=bsize, shuffle=False)\n",
    "\n",
    "# Configure models for 10-class classification\n",
    "print(\"Configuring models...\")\n",
    "MNIST_Classes = 10\n",
    "FashionMNIST_Classes = 10\n",
    "\n",
    "modelMNIST.classifier[1] = nn.Conv2d(512, MNIST_Classes, kernel_size=(1, 1), stride=(1, 1))\n",
    "modelMNIST.num_classes = MNIST_Classes\n",
    "\n",
    "modelFashionMNIST.classifier[1] = nn.Conv2d(512, FashionMNIST_Classes, kernel_size=(1, 1), stride=(1, 1))\n",
    "modelFashionMNIST.num_classes = FashionMNIST_Classes\n",
    "\n",
    "# Enhanced optimizers based on research recommendations\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizerMNIST = optim.SGD(modelMNIST.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizerFashionMNIST = optim.SGD(modelFashionMNIST.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING WATERMARKED MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train MNIST model with watermark embedding\n",
    "print(\"\\nTraining MNIST model with embedded watermarks...\")\n",
    "finedTunedModelMNIST, mnist_watermark_history = enhanced_train_model(\n",
    "    modelMNIST, trainloaderMNIST, optimizerMNIST, criterion, \n",
    "    trigger_mnist, num_epochs=20\n",
    ")\n",
    "\n",
    "# Train FashionMNIST model with watermark embedding\n",
    "print(\"\\nTraining FashionMNIST model with embedded watermarks...\")\n",
    "finedTunedModelFashionMNIST, fashion_watermark_history = enhanced_train_model(\n",
    "    modelFashionMNIST, trainloaderFashionMNIST, optimizerFashionMNIST, criterion, \n",
    "    trigger_fashion, num_epochs=20\n",
    ")\n",
    "\n",
    "# Test models on clean datasets\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING TRAINED MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def test_model(model, dataloader, criterion, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Testing\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    accuracy = correct / total * 100\n",
    "    \n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "# Test both models\n",
    "print(\"Testing MNIST model on clean test set...\")\n",
    "test_loss_MNIST, test_accuracy_MNIST = test_model(finedTunedModelMNIST, testloaderMNIST, criterion)\n",
    "print(f\"MNIST - Test Loss: {test_loss_MNIST:.4f}, Test Accuracy: {test_accuracy_MNIST:.2f}%\")\n",
    "\n",
    "print(\"Testing FashionMNIST model on clean test set...\")\n",
    "test_loss_FashionMNIST, test_accuracy_FashionMNIST = test_model(finedTunedModelFashionMNIST, testloaderFashionMNIST, criterion)\n",
    "print(f\"FashionMNIST - Test Loss: {test_loss_FashionMNIST:.4f}, Test Accuracy: {test_accuracy_FashionMNIST:.2f}%\")\n",
    "\n",
    "# Final watermark validation\n",
    "print(\"\\nFinal watermark validation...\")\n",
    "final_mnist_watermark = validate_watermark_embedding(finedTunedModelMNIST, trigger_mnist, \n",
    "                                                    torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "final_fashion_watermark = validate_watermark_embedding(finedTunedModelFashionMNIST, trigger_fashion,\n",
    "                                                      torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "print(f\"MNIST final watermark accuracy: {final_mnist_watermark:.1%}\")\n",
    "print(f\"FashionMNIST final watermark accuracy: {final_fashion_watermark:.1%}\")\n",
    "\n",
    "# Save models with proper naming\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING WATERMARKED MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def save_watermarked_model(model, dataset_name):\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    model_path = f'models/watermarked_{dataset_name.lower()}_model.pth'\n",
    "    torch.save(model, model_path)\n",
    "    print(f\"✓ Saved watermarked model: {model_path}\")\n",
    "\n",
    "save_watermarked_model(finedTunedModelMNIST, 'MNIST')\n",
    "save_watermarked_model(finedTunedModelFashionMNIST, 'FashionMNIST')\n",
    "\n",
    "# Summary report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WATERMARK EMBEDDING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MNIST Model:\")\n",
    "print(f\"  - Clean test accuracy: {test_accuracy_MNIST:.2f}%\")\n",
    "print(f\"  - Watermark accuracy: {final_mnist_watermark:.1%}\")\n",
    "print(f\"  - Embedding quality: {'✓ Strong' if final_mnist_watermark > 0.9 else '⚠️  Weak'}\")\n",
    "\n",
    "print(f\"\\nFashionMNIST Model:\")\n",
    "print(f\"  - Clean test accuracy: {test_accuracy_FashionMNIST:.2f}%\")\n",
    "print(f\"  - Watermark accuracy: {final_fashion_watermark:.1%}\")\n",
    "print(f\"  - Embedding quality: {'✓ Strong' if final_fashion_watermark > 0.9 else '⚠️  Weak'}\")\n",
    "\n",
    "print(f\"\\n✓ Watermarked models ready for attack evaluation!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
