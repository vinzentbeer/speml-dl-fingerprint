{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9d6d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up transforms and dataloaders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 9.25MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 243kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.76MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.54MB/s]\n",
      "100%|██████████| 26.4M/26.4M [00:00<00:00, 46.9MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 1.41MB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 21.5MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "# --- 1. SETUP: Define Transforms and Load Datasets ---\n",
    "print(\"Setting up transforms and dataloaders...\")\n",
    "\n",
    "# Define the transformation pipeline\n",
    "TRANSFORM = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert 1-channel grayscale to 3-channel for models expecting RGB\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "# Using a try-except block for robustness in case of download issues\n",
    "try:\n",
    "    ds_mnist_train = MNIST(root='./data/raw/MNIST', train=True, download=True, transform=TRANSFORM)\n",
    "    ds_mnist_test = MNIST(root='./data/raw/MNIST', train=False, download=True, transform=TRANSFORM)\n",
    "    ds_fashion_train = FashionMNIST(root='./data/raw/FashionMNIST', train=True, download=True, transform=TRANSFORM)\n",
    "    ds_fashion_test = FashionMNIST(root='./data/raw/FashionMNIST', train=False, download=True, transform=TRANSFORM)\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: Failed to download or load datasets. Error: {e}\")\n",
    "    exit() # Exit the script if data isn't available\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 64\n",
    "dataloaders = {\n",
    "    \"MNIST Train\": DataLoader(ds_mnist_train, batch_size=BATCH_SIZE, shuffle=True),\n",
    "    \"MNIST Test\": DataLoader(ds_mnist_test, batch_size=BATCH_SIZE, shuffle=False),\n",
    "    \"FashionMNIST Train\": DataLoader(ds_fashion_train, batch_size=BATCH_SIZE, shuffle=True),\n",
    "    \"FashionMNIST Test\": DataLoader(ds_fashion_test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "}\n",
    "print(\"Dataloaders created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92507158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_model(model_path):\n",
    "    \"\"\"Loads a full model object that was saved with torch.save(model, path).\"\"\"\n",
    "    print(f\"Loading full model from {model_path}\")\n",
    "    \n",
    "    # Loading is a single step. No need to instantiate the class first.\n",
    "    # Use map_location for portability (e.g., loading a GPU-trained model on a CPU)\n",
    "    with torch.serialization.safe_globals([\n",
    "    torchvision.models.squeezenet.SqueezeNet,\n",
    "    torch.nn.modules.container.Sequential,\n",
    "]):\n",
    "        model = torch.load(model_path, map_location=torch.device('cpu'),weights_only=False)\n",
    "    \n",
    "    print(\"Model loaded successfully.\")\n",
    "    return model\n",
    "def get_squeezenet_last_layer(model):\n",
    "    \"\"\"Returns the last trainable layer of a SqueezeNet model.\"\"\"\n",
    "    # The final classification layer in SqueezeNet is a Conv2d layer\n",
    "    # located at index 1 of the 'classifier' sequential module.\n",
    "    return model.classifier[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff8fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_accuracy(model, dataloader, device):\n",
    "    \"\"\"Calculates the accuracy of a given model on a given dataloader.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return (correct / total) * 100 if total > 0 else 0.0\n",
    "\n",
    "def plot_results(results):\n",
    "    \"\"\"Generates and displays bar plots for training and testing accuracies.\"\"\"\n",
    "    model_names = list(results.keys())\n",
    "    \n",
    "    # Extract accuracies for plotting\n",
    "    mnist_train_acc = [res.get(\"MNIST Train\", 0) for res in results.values()]\n",
    "    fashion_train_acc = [res.get(\"FashionMNIST Train\", 0) for res in results.values()]\n",
    "    mnist_test_acc = [res.get(\"MNIST Test\", 0) for res in results.values()]\n",
    "    fashion_test_acc = [res.get(\"FashionMNIST Test\", 0) for res in results.values()]\n",
    "\n",
    "    x = np.arange(len(model_names))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    # --- Plot 1: Training Accuracy ---\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    rects1 = ax.bar(x - width/2, mnist_train_acc, width, label='MNIST Train')\n",
    "    rects2 = ax.bar(x + width/2, fashion_train_acc, width, label='FashionMNIST Train')\n",
    "\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_title('Training Accuracy by Model and Dataset')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_names, rotation=45, ha=\"right\")\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.legend()\n",
    "    ax.bar_label(rects1, padding=3, fmt='%.1f')\n",
    "    ax.bar_label(rects2, padding=3, fmt='%.1f')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Plot 2: Testing Accuracy ---\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    rects3 = ax.bar(x - width/2, mnist_test_acc, width, label='MNIST Test', color='C2')\n",
    "    rects4 = ax.bar(x + width/2, fashion_test_acc, width, label='FashionMNIST Test', color='C3')\n",
    "\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_title('Testing Accuracy by Model and Dataset')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_names, rotation=45, ha=\"right\")\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.legend()\n",
    "    ax.bar_label(rects3, padding=3, fmt='%.1f')\n",
    "    ax.bar_label(rects4, padding=3, fmt='%.1f')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 3. MAIN EVALUATION FUNCTION ---\n",
    "\n",
    "def evaluate_and_plot_model_performance(model_dir, dataloaders_dict):\n",
    "    \"\"\"\n",
    "    Loads all models from a directory, evaluates their accuracy on multiple\n",
    "    datasets, and plots the results.\n",
    "    \"\"\"\n",
    "    # --- Find and Loop Through Models ---\n",
    "    model_files = glob.glob(os.path.join(model_dir, '*.pth'))\n",
    "    if not model_files:\n",
    "        print(f\"No models (*.pth files) found in '{model_dir}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nFound {len(model_files)} models. Starting evaluation...\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for model_file in model_files:\n",
    "        model_name = os.path.basename(model_file)\n",
    "        print(f\"\\n--- Testing Model: {model_name} ---\")\n",
    "        try:\n",
    "            # IMPORTANT: Replace torch.load() with your custom load_full_model() if needed\n",
    "            model = load_full_model(model_file)\n",
    "            model.to(device)\n",
    "            \n",
    "            model_results = {}\n",
    "            for name, loader in dataloaders_dict.items():\n",
    "                if name[0] != model_name[0]:  # Ensure model name matches dataset type\n",
    "                    continue\n",
    "                print(f\"  > Evaluating on {name}...\")\n",
    "                accuracy = evaluate_accuracy(model, loader, device)\n",
    "                print(f\"    - Accuracy: {accuracy:.2f}%\")\n",
    "                model_results[name] = accuracy\n",
    "            \n",
    "            all_results[model_name] = model_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  > FAILED to test {model_name}. Error: {e}\")\n",
    "            \n",
    "    # --- Plotting the collected results ---\n",
    "    if not all_results:\n",
    "        print(\"\\nNo results were collected. Cannot generate plots.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nEvaluation complete. Generating plots...\")\n",
    "    plot_results(all_results)\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9655bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\Desktop\\MasterStudium\\SOSE25\\194.055 Sicherheit, Privacy und Erklärbarkeit in Maschinellem Lernen\\speml-dl-fingerprint\\notebooks\n",
      "\n",
      "Found 10 models. Starting evaluation...\n",
      "Using device: cuda:0\n",
      "\n",
      "--- Testing Model: FMNIST_SN_finetuned_baseline.pth ---\n",
      "Loading full model from models\\FMNIST_SN_finetuned_baseline.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on FashionMNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 91.01%\n",
      "  > Evaluating on FashionMNIST Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 90.17%\n",
      "\n",
      "--- Testing Model: FMNIST_triggerset1_FTAL.pth ---\n",
      "Loading full model from models\\FMNIST_triggerset1_FTAL.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on FashionMNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 10.00%\n",
      "  > Evaluating on FashionMNIST Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 10.00%\n",
      "\n",
      "--- Testing Model: FMNIST_triggerset1_FTLL.pth ---\n",
      "Loading full model from models\\FMNIST_triggerset1_FTLL.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on FashionMNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 16.36%\n",
      "  > Evaluating on FashionMNIST Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 16.26%\n",
      "\n",
      "--- Testing Model: FMNIST_triggerset1_RTAL.pth ---\n",
      "Loading full model from models\\FMNIST_triggerset1_RTAL.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on FashionMNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 10.00%\n",
      "  > Evaluating on FashionMNIST Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 10.00%\n",
      "\n",
      "--- Testing Model: FMNIST_triggerset1_RTLL.pth ---\n",
      "Loading full model from models\\FMNIST_triggerset1_RTLL.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on FashionMNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 5.45%\n",
      "  > Evaluating on FashionMNIST Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 5.33%\n",
      "\n",
      "--- Testing Model: MNIST_SN_finetuned_baseline.pth ---\n",
      "Loading full model from models\\MNIST_SN_finetuned_baseline.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on MNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 98.72%\n",
      "  > Evaluating on MNIST Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 98.75%\n",
      "\n",
      "--- Testing Model: MNIST_triggerset1_FTAL.pth ---\n",
      "Loading full model from models\\MNIST_triggerset1_FTAL.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on MNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 9.87%\n",
      "  > Evaluating on MNIST Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 9.80%\n",
      "\n",
      "--- Testing Model: MNIST_triggerset1_FTLL.pth ---\n",
      "Loading full model from models\\MNIST_triggerset1_FTLL.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on MNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 22.01%\n",
      "  > Evaluating on MNIST Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Accuracy: 22.25%\n",
      "\n",
      "--- Testing Model: MNIST_triggerset1_RTAL.pth ---\n",
      "Loading full model from models\\MNIST_triggerset1_RTAL.pth\n",
      "Model loaded successfully.\n",
      "  > Evaluating on MNIST Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_and_plot_model_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 95\u001b[0m, in \u001b[0;36mevaluate_and_plot_model_performance\u001b[1;34m(model_dir, dataloaders_dict)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  > Evaluating on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m model_results[name] \u001b[38;5;241m=\u001b[39m accuracy\n",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m, in \u001b[0;36mevaluate_accuracy\u001b[1;34m(model, dataloader, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (correct \u001b[38;5;241m/\u001b[39m total) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "results = evaluate_and_plot_model_performance(model_dir=\"models\", dataloaders_dict=dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b116b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
