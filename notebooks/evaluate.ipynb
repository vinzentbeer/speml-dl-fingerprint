{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed97d7d-526f-4cfe-81e7-f56eb2bd4cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images in ..\\WatermarkNN\\data\\trigger_set\\pics\n",
      "Found 0 images in ..\\WatermarkNN\\data\\trigger_set\\pics\n",
      "✓ Evaluation datasets loaded successfully\n",
      "\n",
      "=== Evaluating Original Watermarked MNIST Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating clean accuracy: 100%|██████████| 100/100 [00:05<00:00, 18.84it/s]\n",
      "Evaluating clean accuracy: 100%|██████████| 600/600 [00:19<00:00, 30.08it/s]\n",
      "Evaluating watermark retention: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating FTLL Attacked MNIST Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating clean accuracy: 100%|██████████| 100/100 [00:03<00:00, 26.73it/s]\n",
      "Evaluating clean accuracy: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 241\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# Perform comprehensive evaluation on both datasets\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m mnist_results \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_evaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMNIST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader_mnist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_mnist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigger_mnist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m fashion_results \u001b[38;5;241m=\u001b[39m load_and_evaluate_models(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFashionMNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_loader_fashion, train_loader_fashion, trigger_fashion)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_results_summary\u001b[39m(results_list, dataset_name):\n",
      "Cell \u001b[0;32mIn[1], line 228\u001b[0m, in \u001b[0;36mload_and_evaluate_models\u001b[0;34m(dataset_name, clean_test_loader, clean_train_loader, trigger_dataset)\u001b[0m\n\u001b[1;32m    225\u001b[0m attacked_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_type\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Attacked \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Model ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 228\u001b[0m attack_results \u001b[38;5;241m=\u001b[39m \u001b[43mcomprehensive_model_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattacked_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigger_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mattack_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(attack_results)\n\u001b[1;32m    233\u001b[0m attacked_model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Free GPU memory\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 126\u001b[0m, in \u001b[0;36mcomprehensive_model_evaluation\u001b[0;34m(model, clean_test_loader, clean_train_loader, trigger_dataset, model_name, device)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Evaluate primary task performance\u001b[39;00m\n\u001b[1;32m    124\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m evaluate_model_accuracy(model, clean_test_loader, device)\n\u001b[0;32m--> 126\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Evaluate watermark retention\u001b[39;00m\n\u001b[1;32m    128\u001b[0m watermark_results \u001b[38;5;241m=\u001b[39m evaluate_watermark_retention(model, trigger_dataset, device)\n",
      "Cell \u001b[0;32mIn[1], line 64\u001b[0m, in \u001b[0;36mevaluate_model_accuracy\u001b[0;34m(model, test_dataloader, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     62\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 64\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcorrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  # Allow duplicate OpenMP library loading\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "class TriggerDatasetPaper(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the trigger images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = glob.glob(os.path.join(root_dir, '*.jpg'))\n",
    "        self.image_paths.extend(glob.glob(os.path.join(root_dir, '*.png'))) # Also find .png\n",
    "        print(f\"Found {len(self.image_paths)} images in {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Extract label from filename like \"image_0_label_7.jpeg\" -> 7\n",
    "        try:\n",
    "            filename = os.path.basename(img_path)\n",
    "            label_str = str(int(filename.split('.')[0])%10)\n",
    "            label = int(label_str)\n",
    "        except (IndexError, ValueError) as e:\n",
    "            raise ValueError(f\"Could not parse label from filename: {img_path}. Expected format 'x.jpeg'\") from e\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def evaluate_model_accuracy(model, test_dataloader, device='cuda'):\n",
    "    \"\"\"Evaluate model accuracy on clean test data\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_dataloader, desc=\"Evaluating clean accuracy\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    if(total == 0):\n",
    "        accuracy = 0 \n",
    "    else:\n",
    "        accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate_model_accuracy_train(model, train_dataloader, device='cuda'):\n",
    "    \"\"\"Evaluate model accuracy on clean test data\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(train_dataloader, desc=\"Evaluating train accuracy\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    if(total == 0):\n",
    "        accuracy = 0 \n",
    "    else:\n",
    "        accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_watermark_retention(model, trigger_dataset, device='cuda', batch_size=32):\n",
    "    \"\"\"Evaluate how well the model retains watermark associations\"\"\"\n",
    "    model.eval()\n",
    "    trigger_loader = DataLoader(trigger_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(trigger_loader, desc=\"Evaluating watermark retention\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    if(total == 0): \n",
    "        watermark_accuracy = 0 \n",
    "    else:\n",
    "        watermark_accuracy = 100 * correct / total\n",
    "    \n",
    "    return {\n",
    "        'watermark_accuracy': watermark_accuracy,\n",
    "        'predictions': predictions,\n",
    "        'true_labels': true_labels,\n",
    "        'total_samples': total\n",
    "    }\n",
    "\n",
    "def comprehensive_model_evaluation(model, clean_test_loader, clean_train_loader, trigger_dataset, \n",
    "                                 model_name=\"Model\", device='cuda'):\n",
    "    \"\"\"Perform comprehensive evaluation of both primary task and watermark retention\"\"\"\n",
    "    \n",
    "    # Evaluate primary task performance\n",
    "    test_accuracy = evaluate_model_accuracy(model, clean_test_loader, device)\n",
    "\n",
    "    train_accuracy = evaluate_model_accuracy_train(model, clean_train_loader, device)\n",
    "    # Evaluate watermark retention\n",
    "    watermark_results = evaluate_watermark_retention(model, trigger_dataset, device)\n",
    "    \n",
    "    # Calculate attack success metrics\n",
    "    attack_success = watermark_results['watermark_accuracy'] < 50.0  # Below random chance\n",
    "    functionality_preserved = test_accuracy > 80.0  # Maintains reasonable performance\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'watermark_accuracy': watermark_results['watermark_accuracy'],\n",
    "        'watermark_predictions': watermark_results['predictions'],\n",
    "        'watermark_labels': watermark_results['true_labels'],\n",
    "        'attack_success': attack_success,\n",
    "        'functionality_preserved': functionality_preserved,\n",
    "        'overall_attack_effectiveness': attack_success and functionality_preserved\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Setup evaluation environment\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define transforms (matching training pipeline)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load clean test datasets\n",
    "test_mnist = MNIST(root='./data/raw/MNIST', train=False, download=True, transform=transform)\n",
    "test_fashion = FashionMNIST(root='./data/raw/FashionMNIST', train=False, download=True, transform=transform)\n",
    "\n",
    "train_mnist = MNIST(root='./data/raw/MNIST', train=True, download=True, transform=transform)\n",
    "train_fashion = FashionMNIST(root='./data/raw/FashionMNIST', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "test_loader_mnist = DataLoader(\n",
    "    test_mnist, batch_size=100, shuffle=False, \n",
    "    num_workers=18, persistent_workers=True, pin_memory=True\n",
    ")\n",
    "train_loader_mnist = DataLoader(\n",
    "    train_mnist, batch_size=100, shuffle=False, \n",
    "    num_workers=18, persistent_workers=True, pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "test_loader_fashion = DataLoader(\n",
    "    test_fashion, batch_size=100, shuffle=False, \n",
    "    num_workers=18, persistent_workers=True, pin_memory=True\n",
    ")\n",
    "train_loader_fashion = DataLoader(\n",
    "    train_fashion, batch_size=100, shuffle=False, \n",
    "    num_workers=18, persistent_workers=True, pin_memory=True\n",
    ")\n",
    "\n",
    "# Load trigger sets with updated filename parsing\n",
    "trigger_mnist = TriggerDatasetPaper(\"..\\WatermarkNN\\data\\\\trigger_set\\pics\", transform=transform)\n",
    "trigger_fashion = TriggerDatasetPaper(\"..\\WatermarkNN\\data\\\\trigger_set\\pics\", transform=transform)\n",
    "\n",
    "print(\"✓ Evaluation datasets loaded successfully\")\n",
    "\n",
    "def load_and_evaluate_models(dataset_name, clean_test_loader, clean_train_loader, trigger_dataset):\n",
    "    \"\"\"Load all model variants and perform comprehensive evaluation\"\"\"\n",
    "    \n",
    "    # Load original watermarked model\n",
    "    watermarked_model = torch.load(f'./models/watermarked_{dataset_name.lower()}_model.pth', weights_only=False)\n",
    "    # if dataset_name == \"MNIST\":\n",
    "    #     watermarked_model = torch.load('./models/mnist__baseline_NO_watermark.pth', weights_only=False)\n",
    "    # else:\n",
    "    #     watermarked_model = torch.load('./models/fmnist__baseline_NO_watermark.pth', weights_only=False)\n",
    "    \n",
    "    \n",
    "    watermarked_model.to(device)\n",
    "    \n",
    "    # Load all attacked models\n",
    "    attack_types = ['ftll', 'ftal', 'rtll', 'rtal']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Evaluate original watermarked model\n",
    "    print(f\"\\n=== Evaluating Original Watermarked {dataset_name} Model ===\")\n",
    "    original_results = comprehensive_model_evaluation(\n",
    "        watermarked_model, clean_test_loader, clean_train_loader, trigger_dataset, \n",
    "        f\"Original {dataset_name}\", device\n",
    "    )\n",
    "    watermarked_model.to('cpu')  # Free GPU memory\n",
    "    results.append(original_results)\n",
    "    \n",
    "    # Evaluate each attacked model\n",
    "    for attack_type in attack_types:\n",
    "        try:\n",
    "            model_path = f'./models/attacked/{dataset_name.lower()}_{attack_type}_attacked.pth'\n",
    "            attacked_model = torch.load(model_path, weights_only=False)\n",
    "            attacked_model.to(device)\n",
    "            \n",
    "            print(f\"\\n=== Evaluating {attack_type.upper()} Attacked {dataset_name} Model ===\")\n",
    "            attack_results = comprehensive_model_evaluation(\n",
    "                attacked_model, clean_test_loader, trigger_dataset,\n",
    "                f\"{attack_type.upper()} {dataset_name}\", device\n",
    "            )\n",
    "            results.append(attack_results)\n",
    "            attacked_model.to('cpu')  # Free GPU memory\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {attack_type.upper()} attacked model not found for {dataset_name}\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "# Perform comprehensive evaluation on both datasets\n",
    "mnist_results = load_and_evaluate_models(\"MNIST\", test_loader_mnist, train_loader_mnist, trigger_mnist)\n",
    "fashion_results = load_and_evaluate_models(\"FashionMNIST\", test_loader_fashion, train_loader_fashion, trigger_fashion)\n",
    "\n",
    "def create_results_summary(results_list, dataset_name):\n",
    "    \"\"\"Create a comprehensive summary of evaluation results\"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    for result in results_list:\n",
    "        summary_data.append({\n",
    "            'Model': result['model_name'],\n",
    "            'Test Accuracy (%)': f\"{result['test_accuracy']:.2f}\",\n",
    "            'Train Accuracy (%)': f\"{result['train_accuracy']:.2f}\",            \n",
    "            'Watermark Accuracy (%)': f\"{result['watermark_accuracy']:.2f}\",\n",
    "            'Attack Success': \"✓\" if result['attack_success'] else \"✗\",\n",
    "            'Functionality Preserved': \"✓\" if result['functionality_preserved'] else \"✗\",\n",
    "            'Overall Effectiveness': \"✓\" if result['overall_attack_effectiveness'] else \"✗\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"COMPREHENSIVE EVALUATION SUMMARY - {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate comprehensive summaries\n",
    "mnist_summary = create_results_summary(mnist_results, \"MNIST\")\n",
    "fashion_summary = create_results_summary(fashion_results, \"FashionMNIST\")\n",
    "\n",
    "def analyze_attack_effectiveness(results_list, dataset_name):\n",
    "    \"\"\"Analyze and visualize attack effectiveness patterns\"\"\"\n",
    "    \n",
    "    model_names = [r['model_name'] for r in results_list]\n",
    "    clean_accuracies = [r['test_accuracy'] for r in results_list]\n",
    "    watermark_accuracies = [r['watermark_accuracy'] for r in results_list]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Clean accuracy comparison\n",
    "    ax1.bar(range(len(model_names)), clean_accuracies, color='blue', alpha=0.7)\n",
    "    ax1.set_xlabel('Model Variants')\n",
    "    ax1.set_ylabel('Clean Accuracy (%)')\n",
    "    ax1.set_title(f'{dataset_name} - Primary Task Performance')\n",
    "    ax1.set_xticks(range(len(model_names)))\n",
    "    ax1.set_xticklabels([name.split()[-1] for name in model_names], rotation=45)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Add accuracy values on bars\n",
    "    for i, v in enumerate(clean_accuracies):\n",
    "        ax1.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Watermark retention comparison\n",
    "    ax2.bar(range(len(model_names)), watermark_accuracies, color='red', alpha=0.7)\n",
    "    ax2.set_xlabel('Model Variants')\n",
    "    ax2.set_ylabel('Watermark Accuracy (%)')\n",
    "    ax2.set_title(f'{dataset_name} - Watermark Retention')\n",
    "    ax2.set_xticks(range(len(model_names)))\n",
    "    ax2.set_xticklabels([name.split()[-1] for name in model_names], rotation=45)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.axhline(y=50, color='green', linestyle='--', alpha=0.7, label='Random Chance')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Add accuracy values on bars\n",
    "    for i, v in enumerate(watermark_accuracies):\n",
    "        ax2.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/{dataset_name.lower()}_attack_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical analysis\n",
    "    original_watermark_acc = results_list[0]['watermark_accuracy']\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Attack Effectiveness Analysis:\")\n",
    "    print(f\"Original watermark strength: {original_watermark_acc:.2f}%\")\n",
    "    \n",
    "    for i, result in enumerate(results_list[1:], 1):\n",
    "        attack_name = result['model_name'].split()[0]\n",
    "        watermark_reduction = original_watermark_acc - result['watermark_accuracy']\n",
    "        clean_preservation = result['test_accuracy']\n",
    "        \n",
    "        print(f\"{attack_name}: -{watermark_reduction:.2f}% watermark retention, \"\n",
    "              f\"{clean_preservation:.2f}% clean accuracy preserved\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Perform detailed analysis\n",
    "analyze_attack_effectiveness(mnist_results, \"MNIST\")\n",
    "analyze_attack_effectiveness(fashion_results, \"FashionMNIST\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WATERMARK ROBUSTNESS EVALUATION COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ Primary task performance measured for all model variants\")\n",
    "print(\"✓ Watermark retention assessed across all attack types\")\n",
    "print(\"✓ Attack effectiveness quantified and visualized\")\n",
    "print(\"✓ Results saved to ./results/ directory\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
